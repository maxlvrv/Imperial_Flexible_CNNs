{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([3, 36, 138])\n",
      "truck   car plane   cat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " #===================================================== Import libraries ================================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn \n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from models.VGG16_with_flex_v6 import *\n",
    "\n",
    "\n",
    "# =================================================== Prepare the dataset ===============================================================================\n",
    "\n",
    "mean_cifar10 = [0.485, 0.456, 0.406]  # Mean and Std value hase been taken from a github implmentation online.\n",
    "std_cifar10 = [0.229, 0.224, 0.225]\n",
    "batch_size = 100\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../FlexibleCNNs/data', train=True, download= True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../FlexibleCNNs/data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # 10 Classes of the cifar-10\n",
    "\n",
    "# ========================================== Visualising the dataset ==========================================================================\n",
    "std= torch.FloatTensor(std_cifar10)\n",
    "mean = torch.FloatTensor(mean_cifar10)\n",
    "mean = mean[:,None,None]\n",
    "std = std[:,None,None]\n",
    "def imshow(img):\n",
    "    print(img.size())\n",
    "    img = img*std + mean     # unnormalize\n",
    "    \n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38,225,246 total parameters.\n",
      "38,225,246 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================== Model initialisation, Loss function and Optimizer =====================================\n",
    "model = VGG16()\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.001,momentum = 0.9,weight_decay = 0.006)\n",
    "schedule = torch.optim.lr_scheduler.StepLR(optimizer,step_size=20,gamma = 0.7)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} trainable parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): FlexiLayer1(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout2d(p=0.3, inplace=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): FlexiLayer2(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout2d(p=0.4, inplace=False)\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): FlexiLayer3(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Dropout2d(p=0.4, inplace=False)\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): FlexiLayer4_2(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Dropout2d(p=0.4, inplace=False)\n",
       "  )\n",
       "  (block5): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Dropout2d(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0   Loss:  1108.1746985912323   Train Accuracy : 16.092\n",
      "\n",
      "\n",
      "Test accuracy: 14 %\n",
      "Epoch:  1   Loss:  1014.654732465744   Train Accuracy : 21.526\n",
      "\n",
      "\n",
      "Test accuracy: 19 %\n",
      "Epoch:  2   Loss:  959.8329459428787   Train Accuracy : 26.302\n",
      "\n",
      "\n",
      "Test accuracy: 27 %\n",
      "Epoch:  3   Loss:  915.2828813791275   Train Accuracy : 30.958\n",
      "\n",
      "\n",
      "Test accuracy: 34 %\n",
      "Epoch:  4   Loss:  882.7115012407303   Train Accuracy : 34.37\n",
      "\n",
      "\n",
      "Test accuracy: 39 %\n",
      "Epoch:  5   Loss:  846.5529549121857   Train Accuracy : 37.814\n",
      "\n",
      "\n",
      "Test accuracy: 44 %\n",
      "Epoch:  6   Loss:  819.4295432567596   Train Accuracy : 40.15\n",
      "\n",
      "\n",
      "Test accuracy: 47 %\n",
      "Epoch:  7   Loss:  794.3402208089828   Train Accuracy : 42.854\n",
      "\n",
      "\n",
      "Test accuracy: 50 %\n",
      "Epoch:  8   Loss:  774.0328947305679   Train Accuracy : 45.33\n",
      "\n",
      "\n",
      "Test accuracy: 53 %\n",
      "Epoch:  9   Loss:  749.4468021392822   Train Accuracy : 47.584\n",
      "\n",
      "\n",
      "Test accuracy: 55 %\n",
      "Epoch:  10   Loss:  732.0258188247681   Train Accuracy : 49.396\n",
      "\n",
      "\n",
      "Test accuracy: 57 %\n",
      "Epoch:  11   Loss:  714.1534214019775   Train Accuracy : 51.038\n",
      "\n",
      "\n",
      "Test accuracy: 59 %\n",
      "Epoch:  12   Loss:  697.1317917108536   Train Accuracy : 52.732\n",
      "\n",
      "\n",
      "Test accuracy: 60 %\n",
      "Epoch:  13   Loss:  680.7886379957199   Train Accuracy : 54.208\n",
      "\n",
      "\n",
      "Test accuracy: 61 %\n",
      "Epoch:  14   Loss:  669.0700472593307   Train Accuracy : 54.788\n",
      "\n",
      "\n",
      "Test accuracy: 62 %\n",
      "Epoch:  15   Loss:  657.3195357322693   Train Accuracy : 56.15\n",
      "\n",
      "\n",
      "Test accuracy: 63 %\n",
      "Epoch:  16   Loss:  645.8252215385437   Train Accuracy : 57.174\n",
      "\n",
      "\n",
      "Test accuracy: 65 %\n",
      "Epoch:  17   Loss:  633.9157321453094   Train Accuracy : 57.916\n",
      "\n",
      "\n",
      "Test accuracy: 65 %\n",
      "Epoch:  18   Loss:  622.8933820724487   Train Accuracy : 58.948\n",
      "\n",
      "\n",
      "Test accuracy: 67 %\n",
      "Epoch:  19   Loss:  612.3343883752823   Train Accuracy : 59.806\n",
      "\n",
      "\n",
      "Test accuracy: 68 %\n",
      "Epoch:  20   Loss:  594.7947472333908   Train Accuracy : 61.434\n",
      "\n",
      "\n",
      "Test accuracy: 69 %\n",
      "Epoch:  21   Loss:  585.1881878376007   Train Accuracy : 62.134\n",
      "\n",
      "\n",
      "Test accuracy: 69 %\n",
      "Epoch:  22   Loss:  576.6269878745079   Train Accuracy : 62.772\n",
      "\n",
      "\n",
      "Test accuracy: 70 %\n",
      "Epoch:  23   Loss:  569.6926228404045   Train Accuracy : 63.282\n",
      "\n",
      "\n",
      "Test accuracy: 71 %\n",
      "Epoch:  24   Loss:  561.8930523395538   Train Accuracy : 63.898\n",
      "\n",
      "\n",
      "Test accuracy: 71 %\n",
      "Epoch:  25   Loss:  556.3614331483841   Train Accuracy : 64.404\n",
      "\n",
      "\n",
      "Test accuracy: 72 %\n",
      "Epoch:  26   Loss:  553.2212671041489   Train Accuracy : 64.678\n",
      "\n",
      "\n",
      "Test accuracy: 72 %\n",
      "Epoch:  27   Loss:  542.4464896917343   Train Accuracy : 65.978\n",
      "\n",
      "\n",
      "Test accuracy: 73 %\n",
      "Epoch:  28   Loss:  537.3315986990929   Train Accuracy : 65.976\n",
      "\n",
      "\n",
      "Test accuracy: 73 %\n",
      "Epoch:  29   Loss:  530.734080016613   Train Accuracy : 66.398\n",
      "\n",
      "\n",
      "Test accuracy: 74 %\n",
      "Epoch:  30   Loss:  526.1430822014809   Train Accuracy : 67.032\n",
      "\n",
      "\n",
      "Test accuracy: 75 %\n",
      "Epoch:  31   Loss:  523.9887670874596   Train Accuracy : 67.298\n",
      "\n",
      "\n",
      "Test accuracy: 74 %\n",
      "Epoch:  32   Loss:  516.3308434486389   Train Accuracy : 67.694\n",
      "\n",
      "\n",
      "Test accuracy: 75 %\n",
      "Epoch:  33   Loss:  510.2337489724159   Train Accuracy : 68.498\n",
      "\n",
      "\n",
      "Test accuracy: 75 %\n",
      "Epoch:  34   Loss:  508.18205404281616   Train Accuracy : 68.356\n",
      "\n",
      "\n",
      "Test accuracy: 75 %\n",
      "Epoch:  35   Loss:  501.29868853092194   Train Accuracy : 69.024\n",
      "\n",
      "\n",
      "Test accuracy: 77 %\n",
      "Epoch:  36   Loss:  496.58183282613754   Train Accuracy : 69.576\n",
      "\n",
      "\n",
      "Test accuracy: 77 %\n",
      "Epoch:  37   Loss:  491.17705804109573   Train Accuracy : 69.876\n",
      "\n",
      "\n",
      "Test accuracy: 76 %\n",
      "Epoch:  38   Loss:  488.31844341754913   Train Accuracy : 70.186\n",
      "\n",
      "\n",
      "Test accuracy: 77 %\n",
      "Epoch:  39   Loss:  487.6440512537956   Train Accuracy : 70.284\n",
      "\n",
      "\n",
      "Test accuracy: 77 %\n",
      "Epoch:  40   Loss:  465.59038656949997   Train Accuracy : 71.91\n",
      "\n",
      "\n",
      "Test accuracy: 78 %\n",
      "Epoch:  41   Loss:  458.7675569653511   Train Accuracy : 72.496\n",
      "\n",
      "\n",
      "Test accuracy: 78 %\n",
      "Epoch:  42   Loss:  454.7538133263588   Train Accuracy : 72.654\n",
      "\n",
      "\n",
      "Test accuracy: 78 %\n",
      "Epoch:  43   Loss:  452.12099117040634   Train Accuracy : 73.026\n",
      "\n",
      "\n",
      "Test accuracy: 79 %\n",
      "Epoch:  44   Loss:  450.72501677274704   Train Accuracy : 73.13\n",
      "\n",
      "\n",
      "Test accuracy: 79 %\n",
      "Epoch:  45   Loss:  441.85249000787735   Train Accuracy : 73.518\n",
      "\n",
      "\n",
      "Test accuracy: 79 %\n",
      "Epoch:  46   Loss:  440.546757876873   Train Accuracy : 73.708\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  47   Loss:  442.05958181619644   Train Accuracy : 73.738\n",
      "\n",
      "\n",
      "Test accuracy: 79 %\n",
      "Epoch:  48   Loss:  437.0390566587448   Train Accuracy : 74.014\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  49   Loss:  433.71319085359573   Train Accuracy : 74.156\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  50   Loss:  429.2738356590271   Train Accuracy : 74.73\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  51   Loss:  427.16547054052353   Train Accuracy : 74.944\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  52   Loss:  423.88937306404114   Train Accuracy : 75.116\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  53   Loss:  419.93614184856415   Train Accuracy : 75.186\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  54   Loss:  418.8156213760376   Train Accuracy : 75.408\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  55   Loss:  418.39077693223953   Train Accuracy : 75.372\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  56   Loss:  414.68971079587936   Train Accuracy : 75.678\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  57   Loss:  411.0951140522957   Train Accuracy : 75.988\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  58   Loss:  408.71791219711304   Train Accuracy : 76.072\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  59   Loss:  406.5925694704056   Train Accuracy : 76.204\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  60   Loss:  393.3664698600769   Train Accuracy : 77.234\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  61   Loss:  385.0165537595749   Train Accuracy : 77.928\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  62   Loss:  381.4794660806656   Train Accuracy : 78.138\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  63   Loss:  381.9609131217003   Train Accuracy : 77.992\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  64   Loss:  376.51217925548553   Train Accuracy : 78.394\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  65   Loss:  375.76359647512436   Train Accuracy : 78.682\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  66   Loss:  373.1577080786228   Train Accuracy : 78.576\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  67   Loss:  376.8648228049278   Train Accuracy : 78.592\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  68   Loss:  367.2072063982487   Train Accuracy : 79.134\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  69   Loss:  367.00836968421936   Train Accuracy : 79.016\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  70   Loss:  363.45288971066475   Train Accuracy : 79.49\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  71   Loss:  362.1176174879074   Train Accuracy : 79.382\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  72   Loss:  364.95851969718933   Train Accuracy : 79.172\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  73   Loss:  358.80564945936203   Train Accuracy : 79.658\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  74   Loss:  361.8749732673168   Train Accuracy : 79.462\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  75   Loss:  358.88445204496384   Train Accuracy : 79.744\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  76   Loss:  357.0278990864754   Train Accuracy : 79.918\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  77   Loss:  356.2230992913246   Train Accuracy : 79.864\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  78   Loss:  352.7800169289112   Train Accuracy : 80.14\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  79   Loss:  352.28507125377655   Train Accuracy : 80.19\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  80   Loss:  339.4160695374012   Train Accuracy : 81.098\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  81   Loss:  335.14158791303635   Train Accuracy : 81.342\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  82   Loss:  330.87002697587013   Train Accuracy : 81.434\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  83   Loss:  328.82421562075615   Train Accuracy : 81.636\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  84   Loss:  326.93121126294136   Train Accuracy : 82.032\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  85   Loss:  322.2179149389267   Train Accuracy : 82.134\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  86   Loss:  321.0666604042053   Train Accuracy : 82.292\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  87   Loss:  320.58622375130653   Train Accuracy : 82.23\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  88   Loss:  321.3102417588234   Train Accuracy : 82.4\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  89   Loss:  316.74133908748627   Train Accuracy : 82.524\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  90   Loss:  320.63548853993416   Train Accuracy : 82.132\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  91   Loss:  315.57916498184204   Train Accuracy : 82.678\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  92   Loss:  317.14243748784065   Train Accuracy : 82.636\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  93   Loss:  315.40224701166153   Train Accuracy : 82.732\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  94   Loss:  315.44751355051994   Train Accuracy : 82.56\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  95   Loss:  311.96745148301125   Train Accuracy : 83.096\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 85 %\n",
      "Epoch:  96   Loss:  310.3387657701969   Train Accuracy : 82.86\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  97   Loss:  307.6397636830807   Train Accuracy : 83.134\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  98   Loss:  306.6290280222893   Train Accuracy : 83.204\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  99   Loss:  305.420607149601   Train Accuracy : 83.326\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  100   Loss:  295.02561515569687   Train Accuracy : 84.128\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  101   Loss:  291.9877229630947   Train Accuracy : 84.304\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  102   Loss:  289.1011901795864   Train Accuracy : 84.518\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  103   Loss:  286.94817340373993   Train Accuracy : 84.594\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  104   Loss:  286.0621531009674   Train Accuracy : 84.882\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  105   Loss:  281.9245910346508   Train Accuracy : 85.076\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  106   Loss:  281.0683969259262   Train Accuracy : 84.968\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  107   Loss:  279.8320509493351   Train Accuracy : 85.014\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  108   Loss:  279.16016283631325   Train Accuracy : 84.95\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  109   Loss:  277.073181450367   Train Accuracy : 85.266\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  110   Loss:  276.85133722424507   Train Accuracy : 85.298\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  111   Loss:  274.62690088152885   Train Accuracy : 85.514\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  112   Loss:  274.1513432562351   Train Accuracy : 85.488\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  113   Loss:  274.62831327319145   Train Accuracy : 85.424\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  114   Loss:  272.6029975414276   Train Accuracy : 85.468\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  115   Loss:  270.37690952420235   Train Accuracy : 85.748\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  116   Loss:  275.7011960744858   Train Accuracy : 85.374\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  117   Loss:  270.06201711297035   Train Accuracy : 85.726\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  118   Loss:  269.40383848547935   Train Accuracy : 85.84\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  119   Loss:  269.70758560299873   Train Accuracy : 85.772\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  120   Loss:  259.9493969976902   Train Accuracy : 86.144\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  121   Loss:  256.9788357615471   Train Accuracy : 86.754\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  122   Loss:  252.34751841425896   Train Accuracy : 87.076\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  123   Loss:  249.7437922656536   Train Accuracy : 87.074\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  124   Loss:  250.56808385252953   Train Accuracy : 87.126\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  125   Loss:  248.2699744105339   Train Accuracy : 87.292\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  126   Loss:  246.09368574619293   Train Accuracy : 87.35\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  127   Loss:  246.61777105927467   Train Accuracy : 87.494\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  128   Loss:  244.39106279611588   Train Accuracy : 87.604\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  129   Loss:  246.35680612921715   Train Accuracy : 87.284\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  130   Loss:  242.67878153920174   Train Accuracy : 87.588\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  131   Loss:  242.9630921781063   Train Accuracy : 87.512\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  132   Loss:  242.64954361319542   Train Accuracy : 87.626\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  133   Loss:  242.27178984880447   Train Accuracy : 87.656\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  134   Loss:  240.90919163823128   Train Accuracy : 87.58\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  135   Loss:  238.5212150812149   Train Accuracy : 87.848\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  136   Loss:  234.93802374601364   Train Accuracy : 87.808\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  137   Loss:  236.20173189044   Train Accuracy : 87.892\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  138   Loss:  234.058380484581   Train Accuracy : 88.236\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  139   Loss:  238.08565437793732   Train Accuracy : 87.806\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  140   Loss:  228.88699978590012   Train Accuracy : 88.642\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  141   Loss:  225.17786693572998   Train Accuracy : 88.794\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  142   Loss:  223.23948362469673   Train Accuracy : 88.834\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  143   Loss:  222.4758937060833   Train Accuracy : 89.032\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  144   Loss:  222.50848470628262   Train Accuracy : 89.062\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  145   Loss:  217.89192734658718   Train Accuracy : 89.292\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  146   Loss:  216.75126333534718   Train Accuracy : 89.374\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  147   Loss:  215.55324855446815   Train Accuracy : 89.376\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  148   Loss:  217.31730145215988   Train Accuracy : 89.364\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  149   Loss:  214.93869584798813   Train Accuracy : 89.6\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  150   Loss:  213.48073279857635   Train Accuracy : 89.516\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  151   Loss:  213.62238074839115   Train Accuracy : 89.534\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  152   Loss:  212.90701708197594   Train Accuracy : 89.592\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  153   Loss:  213.06307949125767   Train Accuracy : 89.644\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  154   Loss:  213.23394457995892   Train Accuracy : 89.524\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  155   Loss:  211.94253760576248   Train Accuracy : 89.602\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  156   Loss:  208.09655080735683   Train Accuracy : 89.75\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  157   Loss:  208.6389116346836   Train Accuracy : 89.746\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  158   Loss:  208.6418950855732   Train Accuracy : 89.862\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  159   Loss:  209.48952631652355   Train Accuracy : 89.88\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  160   Loss:  201.38913248479366   Train Accuracy : 90.346\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  161   Loss:  199.38855689764023   Train Accuracy : 90.516\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  162   Loss:  197.4910300821066   Train Accuracy : 90.43\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  163   Loss:  195.7976066172123   Train Accuracy : 90.852\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  164   Loss:  197.7070355862379   Train Accuracy : 90.74\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  165   Loss:  196.23692762851715   Train Accuracy : 90.632\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  166   Loss:  193.1468688994646   Train Accuracy : 90.894\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  167   Loss:  193.88054375350475   Train Accuracy : 90.822\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  168   Loss:  193.35302706062794   Train Accuracy : 90.884\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  169   Loss:  190.83418613672256   Train Accuracy : 91.088\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  170   Loss:  193.76458029448986   Train Accuracy : 90.95\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  171   Loss:  186.33576226234436   Train Accuracy : 91.38\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  172   Loss:  187.54084473848343   Train Accuracy : 91.254\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  173   Loss:  191.64625933766365   Train Accuracy : 91.024\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  174   Loss:  188.44461011886597   Train Accuracy : 91.286\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  175   Loss:  187.90706595778465   Train Accuracy : 91.15\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  176   Loss:  187.79384556412697   Train Accuracy : 91.262\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  177   Loss:  185.4539028853178   Train Accuracy : 91.288\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  178   Loss:  182.9644345343113   Train Accuracy : 91.622\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  179   Loss:  185.197181224823   Train Accuracy : 91.474\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  180   Loss:  180.00127683579922   Train Accuracy : 91.864\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  181   Loss:  177.81341014802456   Train Accuracy : 91.926\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  182   Loss:  175.30362996459007   Train Accuracy : 92.15\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  183   Loss:  176.77536383271217   Train Accuracy : 92.06\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  184   Loss:  177.27124099433422   Train Accuracy : 91.906\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  185   Loss:  173.3479471951723   Train Accuracy : 92.126\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  186   Loss:  173.46687737107277   Train Accuracy : 92.236\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  187   Loss:  169.4423761665821   Train Accuracy : 92.45\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  188   Loss:  173.18719425797462   Train Accuracy : 92.156\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  189   Loss:  171.6113767027855   Train Accuracy : 92.386\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 87 %\n",
      "Epoch:  190   Loss:  171.12181763350964   Train Accuracy : 92.314\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  191   Loss:  171.1645022034645   Train Accuracy : 92.464\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  192   Loss:  170.61503425240517   Train Accuracy : 92.344\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  193   Loss:  169.45642544329166   Train Accuracy : 92.376\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  194   Loss:  171.89002114534378   Train Accuracy : 92.32\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  195   Loss:  170.12891195714474   Train Accuracy : 92.374\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  196   Loss:  167.60878509283066   Train Accuracy : 92.558\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  197   Loss:  168.15170381963253   Train Accuracy : 92.522\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  198   Loss:  166.65220572054386   Train Accuracy : 92.488\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  199   Loss:  167.25560988485813   Train Accuracy : 92.652\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  200   Loss:  163.10402297973633   Train Accuracy : 92.806\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n"
     ]
    }
   ],
   "source": [
    "# ======================== Function to get the test accuracy ===============================================================================\n",
    "def test():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.train(False)\n",
    "  with torch.no_grad():\n",
    "    for i,(images,labels)in enumerate(testloader):\n",
    "      if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "      outputs = model(Variable(images))\n",
    "      labels = Variable(labels)\n",
    "      _,predicted = outputs.max(1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted.eq(labels)).sum().item()\n",
    "    print('Test accuracy: %d %%' % (\n",
    "  100 * correct / total))\n",
    "  return 100*(correct/total)\n",
    "\n",
    "#======================================================= Training =========================================================================\n",
    "num_epochs = 200  # Train for 150 epochs\n",
    "start_epoch = 0\n",
    "\n",
    "total_step = len(trainloader)\n",
    "train_loss = []  # Store the train_loss per epoch\n",
    "test_accuracy = [] # Store the test_accuracy per epoch\n",
    "for epoch in range(start_epoch,num_epochs+1):\n",
    "  model.train(True)\n",
    "  epoch_loss  = 0\n",
    "  i_count = 0\n",
    "  acc_total = 0\n",
    "  for i,(images,labels) in enumerate(trainloader):\n",
    "    if torch.cuda.is_available():\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "    labels = Variable(labels)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(Variable(images))\n",
    "    loss = criterion(outputs,labels)\n",
    "    epoch_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _,predicted = outputs.max(1)\n",
    "    denom = labels.size(0)\n",
    "    correct = predicted.eq(labels).sum().item()\n",
    "    acc = 100*(correct/denom)\n",
    "    acc_total += acc\n",
    "    i_count = i_count + 1\n",
    "    \n",
    "    #if(i%20 == 0):  # Print the loss per 20 iterations\n",
    "      #print(\"Epoch: \",epoch,\" \",\"Iteration: \",i,\" loss: \",loss.item(),\" Train_iter Accuracy: \",acc)\n",
    "  schedule.step()\n",
    "  train_loss.append(epoch_loss)\n",
    "  print(\"Epoch: \",epoch,\" \",\"Loss: \",epoch_loss,\" \",\"Train Accuracy :\",acc_total/i_count) # Print train accuracy per epoch\n",
    "  print('\\n')\n",
    "  test_acc = test()      # Print the test accuracy per epoch\n",
    "  test_accuracy.append(test_acc)\n",
    "  \n",
    "  if(epoch%50 == 0):       # Save the model every 50 epoch\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'acc' : test_acc,\n",
    "        'optim':optimizer.state_dict(),\n",
    "        'epoch' : epoch\n",
    "    }\n",
    "    path = './models/VGG16-flex-v6-block1-' + 'model_' + str(int(epoch)) +'_' + str(int(test_acc))+'.pth'\n",
    "    torch.save(state,path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 87 %\n",
      "87.62\n",
      "Accuracy of plane : 90 %\n",
      "Accuracy of   car : 90 %\n",
      "Accuracy of  bird : 81 %\n",
      "Accuracy of   cat : 69 %\n",
      "Accuracy of  deer : 85 %\n",
      "Accuracy of   dog : 93 %\n",
      "Accuracy of  frog : 94 %\n",
      "Accuracy of horse : 96 %\n",
      "Accuracy of  ship : 89 %\n",
      "Accuracy of truck : 96 %\n"
     ]
    }
   ],
   "source": [
    "#======================================= Testing ===================================================================================================\n",
    "test_acc = test() # Test error\n",
    "print(test_acc)\n",
    "\n",
    "# Per class accuracy\n",
    "class_correct = list(0. for i in range(10)) # Individual class error\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_acc', test_accuracy]:\n",
    "    plt.plot(\n",
    "        100 * history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
