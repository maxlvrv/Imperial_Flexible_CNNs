{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([3, 36, 138])\n",
      " frog  bird  deer   car\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " #===================================================== Import libraries ================================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn \n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# =================================================== Prepare the dataset ===============================================================================\n",
    "\n",
    "mean_cifar10 = [0.485, 0.456, 0.406]  # Mean and Std value hase been taken from a github implmentation online.\n",
    "std_cifar10 = [0.229, 0.224, 0.225]\n",
    "batch_size = 100\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download= True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # 10 Classes of the cifar-10\n",
    "\n",
    "# ========================================== Visualising the dataset ==========================================================================\n",
    "std= torch.FloatTensor(std_cifar10)\n",
    "mean = torch.FloatTensor(mean_cifar10)\n",
    "mean = mean[:,None,None]\n",
    "std = std[:,None,None]\n",
    "def imshow(img):\n",
    "    print(img.size())\n",
    "    img = img*std + mean     # unnormalize\n",
    "    \n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================= Flexible Layer ================================================================================\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "\n",
    "class FlexiLayer(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1,\n",
    "                 bias=True, padding_mode='zeros'):\n",
    "        kernel_size = kernel_size\n",
    "        stride = stride\n",
    "        padding = padding\n",
    "        dilation = dilation\n",
    "        super(FlexiLayer, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation,\n",
    "            groups, bias, padding_mode)\n",
    "        \n",
    "        \n",
    "        self.threshold1 = nn.parameter.Parameter(torch.randn((100, 64, 30, 30)), requires_grad=True)\n",
    "            \n",
    "    def forward(self, t):\n",
    "        \n",
    "        t_1 = F.relu(F.conv2d(t, self.weight)) # get convolution result\n",
    "        t_2 = F.max_pool2d(t, kernel_size=self.kernel_size, stride=1) # get max result with the same kernel size\n",
    "        #t_2 = torch.cat((t_2, t_2, t_2), 1)\n",
    "        m = nn.Sigmoid()\n",
    "        cond = torch.sub(t_2, self.threshold1)\n",
    "        t_2 = m(cond*50)*t_2 # \n",
    "        t_1 = m(cond*(-50))*t_1 # \n",
    "        t = torch.add(t_2, t_1)\n",
    "        #t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================= VGG-16 Network ================================================================================\n",
    "class VGG16(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(VGG16,self).__init__()\n",
    "\n",
    "    self.block1 = nn.Sequential(\n",
    "                  nn.Conv2d(in_channels = 3,out_channels = 64,kernel_size = 3,padding = 1),\n",
    "                  nn.BatchNorm2d(64),\n",
    "                  nn.ReLU(),\n",
    "                  FlexiLayer(in_channels = 64,out_channels = 64,kernel_size = 3, padding =1),\n",
    "                  nn.BatchNorm2d(64),\n",
    "                  nn.ReLU(),\n",
    "                  #nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                  nn.Dropout2d(0.3))\n",
    "\n",
    "    self.block2 = nn.Sequential(\n",
    "                  nn.Conv2d(in_channels = 64,out_channels = 128,kernel_size = 3,padding = 1),\n",
    "                  nn.BatchNorm2d(128),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Conv2d(in_channels = 128,out_channels = 128,kernel_size = 3, padding =1),\n",
    "                  nn.BatchNorm2d(128),\n",
    "                  nn.ReLU(),\n",
    "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                  nn.Dropout2d(0.4))\n",
    "\n",
    "    self.block3 = nn.Sequential(\n",
    "                  nn.Conv2d(in_channels = 128,out_channels = 256,kernel_size = 3,padding = 1),\n",
    "                  nn.BatchNorm2d(256),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Conv2d(in_channels = 256,out_channels = 256,kernel_size = 3,padding = 1),\n",
    "                  nn.BatchNorm2d(256),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Conv2d(in_channels = 256,out_channels = 256,kernel_size = 3, padding =1),\n",
    "                  nn.BatchNorm2d(256),\n",
    "                  nn.ReLU(),\n",
    "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                  nn.Dropout2d(0.4))\n",
    "\n",
    "    self.block4 = nn.Sequential(\n",
    "                  nn.Conv2d(in_channels = 256,out_channels = 512,kernel_size = 3,padding = 1),\n",
    "                  nn.BatchNorm2d(512),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Conv2d(in_channels = 512,out_channels = 512,kernel_size = 3,padding = 1),\n",
    "                  nn.BatchNorm2d(512),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Conv2d(in_channels = 512,out_channels = 512,kernel_size = 3, padding =1),\n",
    "                  nn.BatchNorm2d(512),\n",
    "                  nn.ReLU(),\n",
    "                  nn.MaxPool2d(kernel_size=2, stride=2) ,\n",
    "                  nn.Dropout2d(0.4))\n",
    "\n",
    "    self.block5 = nn.Sequential(\n",
    "                  nn.Conv2d(in_channels = 512,out_channels = 512,kernel_size = 3,padding = 1),\n",
    "                  nn.BatchNorm2d(512),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Conv2d(in_channels = 512,out_channels = 512,kernel_size = 3,padding = 1),\n",
    "                  nn.BatchNorm2d(512),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Conv2d(in_channels = 512,out_channels = 512,kernel_size = 3, padding =1),\n",
    "                  nn.BatchNorm2d(512),\n",
    "                  nn.ReLU(),\n",
    "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                  nn.Dropout2d(0.5) )\n",
    "\n",
    "    self.fc =     nn.Sequential(\n",
    "                  nn.Linear(512,100),\n",
    "                  nn.Dropout(0.5),\n",
    "                  nn.BatchNorm1d(100),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Dropout(0.5),\n",
    "                  nn.Linear(100,10), )\n",
    "                  \n",
    "                  \n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    out = self.block1(x)\n",
    "    out = self.block2(out)\n",
    "    out = self.block3(out)\n",
    "    out = self.block4(out)\n",
    "    out = self.block5(out)\n",
    "    out = out.view(out.size(0),-1)\n",
    "    out = self.fc(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlavrov/anaconda3/envs/meng/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0   Loss:  1081.6267292499542   Train Accuracy : 18.44\n",
      "\n",
      "\n",
      "Test accuracy: 19 %\n",
      "Epoch:  1   Loss:  944.1387813091278   Train Accuracy : 28.34\n",
      "\n",
      "\n",
      "Test accuracy: 31 %\n",
      "Epoch:  2   Loss:  880.7280458211899   Train Accuracy : 33.398\n",
      "\n",
      "\n",
      "Test accuracy: 38 %\n",
      "Epoch:  3   Loss:  835.5594223737717   Train Accuracy : 37.492\n",
      "\n",
      "\n",
      "Test accuracy: 45 %\n",
      "Epoch:  4   Loss:  799.6720504760742   Train Accuracy : 40.882\n",
      "\n",
      "\n",
      "Test accuracy: 48 %\n",
      "Epoch:  5   Loss:  764.2561674118042   Train Accuracy : 44.548\n",
      "\n",
      "\n",
      "Test accuracy: 53 %\n",
      "Epoch:  6   Loss:  733.0517596006393   Train Accuracy : 47.968\n",
      "\n",
      "\n",
      "Test accuracy: 56 %\n",
      "Epoch:  7   Loss:  698.0382008552551   Train Accuracy : 51.28\n",
      "\n",
      "\n",
      "Test accuracy: 58 %\n",
      "Epoch:  8   Loss:  665.888821721077   Train Accuracy : 54.118\n",
      "\n",
      "\n",
      "Test accuracy: 61 %\n",
      "Epoch:  9   Loss:  638.1468638181686   Train Accuracy : 56.622\n",
      "\n",
      "\n",
      "Test accuracy: 64 %\n",
      "Epoch:  10   Loss:  609.6415465474129   Train Accuracy : 59.324\n",
      "\n",
      "\n",
      "Test accuracy: 66 %\n",
      "Epoch:  11   Loss:  587.7886090278625   Train Accuracy : 61.212\n",
      "\n",
      "\n",
      "Test accuracy: 68 %\n",
      "Epoch:  12   Loss:  563.7351141571999   Train Accuracy : 62.96\n",
      "\n",
      "\n",
      "Test accuracy: 68 %\n",
      "Epoch:  13   Loss:  546.6383403539658   Train Accuracy : 64.43\n",
      "\n",
      "\n",
      "Test accuracy: 71 %\n",
      "Epoch:  14   Loss:  524.6029424667358   Train Accuracy : 66.672\n",
      "\n",
      "\n",
      "Test accuracy: 70 %\n",
      "Epoch:  15   Loss:  506.9339168667793   Train Accuracy : 67.78\n",
      "\n",
      "\n",
      "Test accuracy: 75 %\n",
      "Epoch:  16   Loss:  490.8277980685234   Train Accuracy : 69.18\n",
      "\n",
      "\n",
      "Test accuracy: 75 %\n",
      "Epoch:  17   Loss:  476.2512159347534   Train Accuracy : 70.442\n",
      "\n",
      "\n",
      "Test accuracy: 76 %\n",
      "Epoch:  18   Loss:  458.45375871658325   Train Accuracy : 71.918\n",
      "\n",
      "\n",
      "Test accuracy: 77 %\n",
      "Epoch:  19   Loss:  431.19159013032913   Train Accuracy : 73.934\n",
      "\n",
      "\n",
      "Test accuracy: 78 %\n",
      "Epoch:  20   Loss:  419.26186257600784   Train Accuracy : 75.238\n",
      "\n",
      "\n",
      "Test accuracy: 78 %\n",
      "Epoch:  21   Loss:  407.4663339853287   Train Accuracy : 75.898\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  22   Loss:  398.74449920654297   Train Accuracy : 76.514\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  23   Loss:  389.3213821053505   Train Accuracy : 77.296\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  24   Loss:  378.88400197029114   Train Accuracy : 78.084\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  25   Loss:  374.6032335460186   Train Accuracy : 78.448\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  26   Loss:  368.1997274160385   Train Accuracy : 79.118\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  27   Loss:  362.9142882823944   Train Accuracy : 79.26\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  28   Loss:  351.8235268294811   Train Accuracy : 80.19\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  29   Loss:  344.86476361751556   Train Accuracy : 80.65\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  30   Loss:  335.99575901031494   Train Accuracy : 81.218\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  31   Loss:  332.84719544649124   Train Accuracy : 81.542\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  32   Loss:  328.1456132233143   Train Accuracy : 81.742\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  33   Loss:  317.5699726641178   Train Accuracy : 82.444\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  34   Loss:  315.16553395986557   Train Accuracy : 82.858\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  35   Loss:  312.7692366242409   Train Accuracy : 82.872\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  36   Loss:  303.9647396802902   Train Accuracy : 83.44\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  37   Loss:  298.2057138681412   Train Accuracy : 83.854\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  38   Loss:  297.0796681344509   Train Accuracy : 83.914\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  39   Loss:  273.63963827490807   Train Accuracy : 85.526\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  40   Loss:  267.70622393488884   Train Accuracy : 86.036\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  41   Loss:  261.55627062916756   Train Accuracy : 86.368\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  42   Loss:  259.65866380929947   Train Accuracy : 86.666\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  43   Loss:  252.49190264940262   Train Accuracy : 86.964\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  44   Loss:  248.4520707130432   Train Accuracy : 87.282\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  45   Loss:  244.5494665801525   Train Accuracy : 87.498\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  46   Loss:  244.4283259510994   Train Accuracy : 87.518\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  47   Loss:  241.3901650607586   Train Accuracy : 87.758\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  48   Loss:  236.82193306088448   Train Accuracy : 87.994\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  49   Loss:  234.82954782247543   Train Accuracy : 87.994\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  50   Loss:  232.2385095655918   Train Accuracy : 88.222\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  51   Loss:  227.32994045317173   Train Accuracy : 88.646\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  52   Loss:  228.78572621941566   Train Accuracy : 88.474\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  53   Loss:  225.07721188664436   Train Accuracy : 88.778\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  54   Loss:  219.1637091934681   Train Accuracy : 89.042\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  55   Loss:  214.0028364211321   Train Accuracy : 89.474\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  56   Loss:  216.95856715738773   Train Accuracy : 89.292\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  57   Loss:  211.1161433160305   Train Accuracy : 89.652\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  58   Loss:  211.34465146064758   Train Accuracy : 89.526\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  59   Loss:  193.0485723465681   Train Accuracy : 90.84\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  60   Loss:  185.5845248401165   Train Accuracy : 91.406\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  61   Loss:  179.75520718097687   Train Accuracy : 91.714\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  62   Loss:  176.65862174332142   Train Accuracy : 91.988\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  63   Loss:  177.40052516758442   Train Accuracy : 91.886\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  64   Loss:  173.61234164237976   Train Accuracy : 91.93\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  65   Loss:  172.7093112319708   Train Accuracy : 92.17\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  66   Loss:  168.85249879956245   Train Accuracy : 92.336\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  67   Loss:  167.81886112689972   Train Accuracy : 92.298\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  68   Loss:  167.2405387610197   Train Accuracy : 92.382\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  69   Loss:  166.13257399201393   Train Accuracy : 92.608\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  70   Loss:  163.3860116750002   Train Accuracy : 92.696\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  71   Loss:  160.5800440311432   Train Accuracy : 92.876\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  72   Loss:  160.43107615411282   Train Accuracy : 92.886\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  73   Loss:  160.3680375814438   Train Accuracy : 92.942\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  74   Loss:  158.02629201114178   Train Accuracy : 93.096\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  75   Loss:  157.0182747989893   Train Accuracy : 93.044\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  76   Loss:  152.4391493499279   Train Accuracy : 93.298\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  77   Loss:  157.56745167076588   Train Accuracy : 92.96\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  78   Loss:  157.31697285175323   Train Accuracy : 93.026\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  79   Loss:  138.00970585644245   Train Accuracy : 94.272\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  80   Loss:  132.55125084519386   Train Accuracy : 94.602\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  81   Loss:  125.3428606390953   Train Accuracy : 95.076\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  82   Loss:  124.66031624376774   Train Accuracy : 95.164\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  83   Loss:  124.06558038294315   Train Accuracy : 95.084\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  84   Loss:  122.47282500565052   Train Accuracy : 95.308\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  85   Loss:  124.19161430001259   Train Accuracy : 95.21\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  86   Loss:  117.40890607237816   Train Accuracy : 95.634\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  87   Loss:  118.73398686945438   Train Accuracy : 95.41\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  88   Loss:  117.0912250354886   Train Accuracy : 95.584\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  89   Loss:  117.62310852110386   Train Accuracy : 95.502\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  90   Loss:  117.99868136644363   Train Accuracy : 95.54\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  91   Loss:  115.82108932733536   Train Accuracy : 95.642\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  92   Loss:  115.32484468817711   Train Accuracy : 95.678\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  93   Loss:  113.76860482245684   Train Accuracy : 95.648\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  94   Loss:  114.5220812484622   Train Accuracy : 95.732\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  95   Loss:  111.2622319534421   Train Accuracy : 95.898\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  96   Loss:  110.43868951499462   Train Accuracy : 95.948\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  97   Loss:  111.40563914179802   Train Accuracy : 95.768\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  98   Loss:  112.84611923247576   Train Accuracy : 95.76\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  99   Loss:  102.28880909085274   Train Accuracy : 96.434\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  100   Loss:  98.3267520442605   Train Accuracy : 96.64\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  101   Loss:  94.09270662814379   Train Accuracy : 97.014\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  102   Loss:  90.61036448180676   Train Accuracy : 97.118\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  103   Loss:  89.48924440145493   Train Accuracy : 97.204\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  104   Loss:  90.11351957172155   Train Accuracy : 97.16\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  105   Loss:  88.35058131068945   Train Accuracy : 97.366\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  106   Loss:  86.86749669164419   Train Accuracy : 97.41\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  107   Loss:  86.59930772334337   Train Accuracy : 97.352\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  108   Loss:  87.96741702407598   Train Accuracy : 97.268\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  109   Loss:  88.68800237774849   Train Accuracy : 97.284\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  110   Loss:  86.36761194467545   Train Accuracy : 97.33\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  111   Loss:  84.5160524174571   Train Accuracy : 97.474\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  112   Loss:  86.12625969946384   Train Accuracy : 97.338\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  113   Loss:  83.79308804869652   Train Accuracy : 97.51\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  114   Loss:  83.70116719603539   Train Accuracy : 97.416\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  115   Loss:  85.05741725116968   Train Accuracy : 97.478\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  116   Loss:  84.92593663185835   Train Accuracy : 97.308\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  117   Loss:  82.27825490385294   Train Accuracy : 97.666\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  118   Loss:  83.67901846021414   Train Accuracy : 97.566\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  119   Loss:  78.98592507839203   Train Accuracy : 97.83\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  120   Loss:  76.15250427275896   Train Accuracy : 97.986\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  121   Loss:  74.2087154686451   Train Accuracy : 98.082\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  122   Loss:  71.81587736308575   Train Accuracy : 98.238\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  123   Loss:  72.55138743668795   Train Accuracy : 98.152\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  124   Loss:  71.46119640022516   Train Accuracy : 98.224\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  125   Loss:  70.24916330724955   Train Accuracy : 98.284\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  126   Loss:  68.84402922540903   Train Accuracy : 98.336\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  127   Loss:  70.0985676124692   Train Accuracy : 98.328\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  128   Loss:  70.08144061267376   Train Accuracy : 98.342\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  129   Loss:  68.47528187930584   Train Accuracy : 98.38\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  130   Loss:  69.05516840517521   Train Accuracy : 98.398\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  131   Loss:  68.90279106795788   Train Accuracy : 98.376\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  132   Loss:  68.49610093981028   Train Accuracy : 98.412\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  133   Loss:  67.36683518067002   Train Accuracy : 98.448\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  134   Loss:  65.91382776200771   Train Accuracy : 98.54\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  135   Loss:  66.97930187731981   Train Accuracy : 98.442\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  136   Loss:  66.7979495190084   Train Accuracy : 98.544\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  137   Loss:  65.23536911606789   Train Accuracy : 98.562\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  138   Loss:  67.55776981264353   Train Accuracy : 98.47\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  139   Loss:  64.59725914895535   Train Accuracy : 98.638\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  140   Loss:  64.56366349756718   Train Accuracy : 98.614\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  141   Loss:  63.09317449480295   Train Accuracy : 98.692\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  142   Loss:  61.92681682482362   Train Accuracy : 98.76\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  143   Loss:  61.73380359262228   Train Accuracy : 98.748\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  144   Loss:  61.57747706770897   Train Accuracy : 98.828\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  145   Loss:  60.47637265175581   Train Accuracy : 98.878\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  146   Loss:  59.48782243579626   Train Accuracy : 98.918\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  147   Loss:  61.059689067304134   Train Accuracy : 98.824\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  148   Loss:  59.37367845699191   Train Accuracy : 98.882\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  149   Loss:  60.240638103336096   Train Accuracy : 98.834\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  150   Loss:  59.05077397450805   Train Accuracy : 98.916\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  151   Loss:  59.857291117310524   Train Accuracy : 98.898\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  152   Loss:  59.813191793859005   Train Accuracy : 98.906\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  153   Loss:  57.84431020915508   Train Accuracy : 99.032\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  154   Loss:  59.0044971704483   Train Accuracy : 98.862\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  155   Loss:  58.48573011159897   Train Accuracy : 98.902\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  156   Loss:  57.92533467337489   Train Accuracy : 99.014\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  157   Loss:  57.82498050481081   Train Accuracy : 99.028\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  158   Loss:  57.58986985683441   Train Accuracy : 99.002\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  159   Loss:  57.21436396986246   Train Accuracy : 99.026\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  160   Loss:  56.71404431015253   Train Accuracy : 99.108\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  161   Loss:  56.34733985736966   Train Accuracy : 99.03\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  162   Loss:  55.459349140524864   Train Accuracy : 99.148\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  163   Loss:  55.627436731010675   Train Accuracy : 99.092\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  164   Loss:  55.90184868499637   Train Accuracy : 99.09\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  165   Loss:  55.84636137261987   Train Accuracy : 99.108\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  166   Loss:  55.5087149515748   Train Accuracy : 99.124\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  167   Loss:  55.217055574059486   Train Accuracy : 99.064\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  168   Loss:  54.69955597817898   Train Accuracy : 99.14\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  169   Loss:  55.89002775400877   Train Accuracy : 99.11\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  170   Loss:  54.97939255088568   Train Accuracy : 99.144\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  171   Loss:  54.61542506888509   Train Accuracy : 99.184\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  172   Loss:  54.84237311407924   Train Accuracy : 99.188\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  173   Loss:  53.99264017865062   Train Accuracy : 99.15\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  174   Loss:  54.366130873560905   Train Accuracy : 99.166\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  175   Loss:  53.84609296172857   Train Accuracy : 99.142\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  176   Loss:  53.26180600002408   Train Accuracy : 99.216\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  177   Loss:  53.58922932296991   Train Accuracy : 99.176\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  178   Loss:  54.61484359204769   Train Accuracy : 99.138\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  179   Loss:  53.59935133904219   Train Accuracy : 99.174\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  180   Loss:  53.66187626123428   Train Accuracy : 99.222\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  181   Loss:  54.21109652891755   Train Accuracy : 99.21\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  182   Loss:  53.470035925507545   Train Accuracy : 99.168\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  183   Loss:  52.571760684251785   Train Accuracy : 99.286\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  184   Loss:  53.88363794982433   Train Accuracy : 99.252\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  185   Loss:  53.201758712530136   Train Accuracy : 99.18\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  186   Loss:  52.34430744871497   Train Accuracy : 99.236\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  187   Loss:  51.85753296688199   Train Accuracy : 99.282\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  188   Loss:  52.30757612362504   Train Accuracy : 99.32\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  189   Loss:  52.821446653455496   Train Accuracy : 99.286\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  190   Loss:  51.85567845404148   Train Accuracy : 99.282\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  191   Loss:  52.17931578308344   Train Accuracy : 99.294\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  192   Loss:  52.36979418992996   Train Accuracy : 99.25\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  193   Loss:  51.34395655617118   Train Accuracy : 99.362\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  194   Loss:  52.22018811479211   Train Accuracy : 99.234\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  195   Loss:  51.31500530987978   Train Accuracy : 99.304\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  196   Loss:  51.72313703969121   Train Accuracy : 99.312\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  197   Loss:  51.8864128254354   Train Accuracy : 99.278\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  198   Loss:  51.46830437704921   Train Accuracy : 99.304\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  199   Loss:  51.995884232223034   Train Accuracy : 99.278\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n"
     ]
    }
   ],
   "source": [
    "# =============================================================== Model initialisation, Loss function and Optimizer =====================================\n",
    "model = VGG16()\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.001,momentum = 0.9,weight_decay = 0.006)\n",
    "schedule = torch.optim.lr_scheduler.StepLR(optimizer,step_size=20,gamma = 0.7)\n",
    "\n",
    "\n",
    "# ======================== Function to get the test accuracy ===============================================================================\n",
    "def test():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.train(False)\n",
    "  with torch.no_grad():\n",
    "    for i,(images,labels)in enumerate(testloader):\n",
    "      if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "      outputs = model(Variable(images))\n",
    "      labels = Variable(labels)\n",
    "      _,predicted = outputs.max(1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted.eq(labels)).sum().item()\n",
    "    print('Test accuracy: %d %%' % (\n",
    "  100 * correct / total))\n",
    "  return 100*(correct/total)\n",
    "\n",
    "#======================================================= Training =========================================================================\n",
    "num_epochs = 200  # Train for 200 epochs\n",
    "start_epoch = 0\n",
    "\n",
    "total_step = len(trainloader)\n",
    "train_loss = []  # Store the train_loss per epoch\n",
    "test_accuracy = [] # Store the test_accuracy per epoch\n",
    "for epoch in range(start_epoch,num_epochs):\n",
    "  model.train(True)\n",
    "  schedule.step()\n",
    "  epoch_loss  = 0\n",
    "  i_count = 0\n",
    "  acc_total = 0\n",
    "  for i,(images,labels) in enumerate(trainloader):\n",
    "    if torch.cuda.is_available():\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "    labels = Variable(labels)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(Variable(images))\n",
    "    loss = criterion(outputs,labels)\n",
    "    epoch_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _,predicted = outputs.max(1)\n",
    "    denom = labels.size(0)\n",
    "    correct = predicted.eq(labels).sum().item()\n",
    "    acc = 100*(correct/denom)\n",
    "    acc_total += acc\n",
    "    i_count = i_count + 1\n",
    "    \n",
    "    #if(i%20 == 0):  # Print the loss per 20 iterations\n",
    "      #print(\"Epoch: \",epoch,\" \",\"Iteration: \",i,\" loss: \",loss.item(),\" Train_iter Accuracy: \",acc)\n",
    "  train_loss.append(epoch_loss)\n",
    "  print(\"Epoch: \",epoch,\" \",\"Loss: \",epoch_loss,\" \",\"Train Accuracy :\",acc_total/i_count) # Print train accuracy per epoch\n",
    "  print('\\n')\n",
    "  test_acc = test()      # Print the test accuracy per epoch\n",
    "  test_accuracy.append(test_acc)\n",
    "  \n",
    "  if(epoch%50 == 0):       # Save the model every 50 epoch\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'acc' : test_acc,\n",
    "        'optim':optimizer.state_dict(),\n",
    "        'epoch' : epoch\n",
    "    }\n",
    "    path = './VGG16-flex-v5-block1-' + 'model_' + str(int(epoch)) +'_' + str(int(test_acc))+'.pth'\n",
    "    torch.save(state,path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 90 %\n",
      "90.59\n",
      "Accuracy of plane : 97 %\n",
      "Accuracy of   car : 96 %\n",
      "Accuracy of  bird : 86 %\n",
      "Accuracy of   cat : 72 %\n",
      "Accuracy of  deer : 95 %\n",
      "Accuracy of   dog : 84 %\n",
      "Accuracy of  frog : 94 %\n",
      "Accuracy of horse : 96 %\n",
      "Accuracy of  ship : 95 %\n",
      "Accuracy of truck : 96 %\n"
     ]
    }
   ],
   "source": [
    "#======================================= Testing ===================================================================================================\n",
    "test_acc = test() # Test error\n",
    "print(test_acc)\n",
    "\n",
    "# Per class accuracy\n",
    "class_correct = list(0. for i in range(10)) # Individual class error\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
