{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([3, 36, 138])\n",
      " ship horse  ship   dog\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO19d5Be13Xf7369be+7KItGEATELlZRVDXVKduSI9sjM45iTTxOYmc8E8vxH45n7Bln4rGTzLhpbMmKIquYsiRSjZIoSpREEiRIig29LIAFtvevl3fzxzn3nbOLXWIJUFh89v3NkPvhvve9d9t73znnd4qx1sLDw8PDo/kQ2egOeHh4eHhcGvwL3MPDw6NJ4V/gHh4eHk0K/wL38PDwaFL4F7iHh4dHk8K/wD08PDyaFJf1AjfGvMsYc8QYc9wY84nXq1MeHh4eHheHuVQ/cGNMFMBRAO8EMArgGQC/bK09+Pp1z8PDw8NjLcQu47u3AThurT0JAMaYLwC4H8CaL/BMOmXb2lou45YeHh4e//owPjE9ba3tWdl+OS/wIQBn1b9HAdz+al9oa2vBxz76i5dxSw8PD49/ffiTP/vb06u1X44N3KzSdoE9xhjzcWPMAWPMgWKxfBm38/Dw8PDQuJwX+CiAzerfmwCcX3mStfaT1tpbrbW3ZjKpy7idh4eHh4fG5bzAnwGwyxizzRiTAPARAA+9Pt3y8PDw8LgYLtkGbq2tG2P+I4BHAEQBfMpa+8prvc6zvR/mCzbCNmMM/5XfFxOLchs3BHJ+JpUAACTi8bAtXyjxF+Ua1gb01YD+2kAsPjFD149EomGbO09bhqLRKB+j+zca0o9I5MLfQ+v6GV5LPgd1d0xZnhqub3K+4ePxiIxvT/kby+7z6c89rPpBk5SIS3+yaZqjLM8VAEQgfQeASFKOFYoVAEB/d0fYtmvnFgDA6bPjYdtLr5wCAMwtLgEA6vVaeCweS/CQZHy5bBIA8IvveZO67jYAwLMvHeOWenjsmp3bAQA/feFw2La4MAMA6GnLhG3FJbr/2PQCAGBmScx1fT1dAIClsvTt/MQsAODff/TDWInue38NAJBNpMO2bJK0x2hMLIduP6227u6sZETGnozT4xaPyzy7+arWacwlW1fH6HMUshcSMbqXWlokecsa9igzSi5rWLrn5NhY2HbypecBAG+8866wLcjmAAALvP+WStXwWGmxSPdU/Yg2eH6rhbDt7HPfh8bnH3k6/JzuJWW9Y/iasC3F83DkyR+HbdOnjwIAIsbNg4wlGqGxGGW8jcdpP3X19odtmRw5SlQrtIcr/JcGSnPU0doufUvTNcpVGfPYOTI5v3Mv7b9r1fn/73vfpOt39YZtfX30bEzNzodtpSqNIZOl/kR7h8JjrbvfAAAozC+GbVlLc3pvTwnrxeWQmLDWfhPANy/nGh4eHh4el4bLeoG/HoizRGiDCyXZ5ZINSxeGpABj5VgiQZ+jRkk7LE0axbW6o873fbm06H7d5fzGcgGVzmMpv17nPjakH66/y+7JmoUen62zJMPSvNYEnHRuG0oC5/7GoyKBYwUfnFJS3ez8HACgUhPJw90+HpP+tmRI8uhooe/GItLHaIzu1ZIdCNvm5kjKTcRk27z3XW8GAMzMkiRRroj00NtJUku9mg/bIrx+w5u6pS1Cbb09dH4yKeNMZUkDeOXYaNh2cuQMAGD7FpG6NvWSBLllE3labaqJJBvjuTk2Oh22mdUoeNdvluzjMelHIk5rlU1IW+A2iLuWWkanQaXVmsVYu3NaHACYKM2lTdNFykrCL7m5bMg+dRqUUfEbgRsrL3JC7b8Wfg4m5iZkfO00vt4uceld4D1Z4mciFZM+zrIUP1sQaTvG96pXVnlIXF+rxfDz4shLdI1p0QS6B7Zxt5WEzFpNnOeqpp6NWo0lZLV26TSNJZvJhm0tOdoLeV7kqNKqYzz3XV2iWSYSNEdaUl9cbAUAPH2S9tpin+yn8wFd44NvfXvY9s67SJs5O3oubHv4298DAEzycxOti4Qf43lORuV5TBrHEa5fAveh9B4eHh5NCv8C9/Dw8GhSbLgJJZUlFUibGJwZQ5tQDBNuEUekWDExtOSYzNJe6EyCGKU+OTgTSq0uw49EL9SDbY0+R6NyXpLJLJRJHYqq8x3pukw9DwlTGV/gzCP81yg1MVSNdRt/jimVHnPLx3TbzbvDzxUmvyYmF8K28+OkQs/NS9uOXdcBAPa9YQ8A4KknngiPbWMTxx233Ry25VmFbuvoDNtSKTLDOEJUWVdgA1JJE0pMcOuXTLeGbaU6rdEmwyadTrn+kROkci8tKTMMz/npUTELOGK1rZX2wu7tfTKWATIV7NkkanNnVkxOK9HOrGA0ofYOm35SUVnHOJtVzCqmsxqry1br+zwPDUUe19j8ETizmpV+pZxZL6LIQzbJKWthaE6s16mxEYi6X1qaBADMnz0Rtm3fS+udUGuVcHuxSup7flGZE0p0/aWiMnWweS5Qpj6ZXUKbMsPMLdD6LeTlGq1JWpfWjJDF937wgwCAnZuJ9BydlDV+9DEiScfHhER3cx5Tg3FmztDhIKrmj9viyuHBmU8D5TjQwsTjxOkpAMAZI+RkaweRl1vbhNi8cx89f2+8fk/YduYMmV8++6WvAgA6k2LmGeQFLNVkLxScyVMue1F4CdzDw8OjSbHhEniaiTTbEKlB3AiNaqNfaedeFLHC4rW00jXUJdAA/cJqt0BxI2RpXp3vXO+0BO4EiIQiriJMiDX4ukaL/eEllPQcStmKxHRSS3ChtK06K/e0rj9rL9fLr4gHZ5bdqHp7hSjcunkvAGB+UYioXbvIpevaa4lM2jIoP/1Okk2r2Kvu3jYAyzUSJwGkWJpapn3w53qQDJtqLGnauFyjs53WtneQbnb0uGRo+OZ3fwgAKBRFAs9yQFilqhaQMTdPxNlCQQijQ2fIZbBcFunvmq19WAsx1sYSivANtUKl+SWYoEwmk8vOAUIFDSWlRVr+rCU9x4HXa9S2jOjiY4rXhGWJPaJEcOcC63aYc60DgNOHfkp9q8vYhzYRMd3QY2GJtKud5OhSQ+Z7olziccpzUOW7BXZtErOk1qBQZUlZSdtBie4xtH1L2Pbr//YBAMAWdtGbKS6Fx86dJ4Lw3FkhtAMeQ6OuNFyeX+fiq1193VQ6F01ANCi9PxpO08/QmE9OiSZQMvTuefgbXwnbOuI01j033hS2jZ4ZoXsx+To9LgTuEDsaRCMyH6WKkNXrhZfAPTw8PJoU/gXu4eHh0aTYcBOKy48SKF/X0IQCrcJSVyPsqxwxYhpJsFqmtE+k2J6yLLKSo9xqrK5CqbeRGJtydH50JjdSGYn4k/6QuhXREaR8/Ygyq7hIuCCQqbaN5URUoFQ8901tiRATiiIxV6Cq1K9qhfydFxeE6YzwWFrahWqqlYmYKcyQSppNyzg5cBOZtBAvbg3SWSEgXZRZSApZ6XkEbGZS/TYRunCxJKpxndX7BpuW2hU59EZWSedmZsK26Skanya5I0xOdXKkZ0taVNOxKRrn6bOiBo+cpev9JkfEabi5SsbEFBEN96Tyz3d+/M7fWDG4iVUczWvOd1qZLhzJHouziUYF7Lqdq6Mu42y+0qYcF6lZ5/krq/108iyZo7b2i8kokSE/6YKyfgS846K8Vh1tbeGxvgb7qCviN88WloXFtdX+8wUxczaYaM0EihjOk2kmVlWE6ST1d7pEZHstInNaZ4K1buWexRq1lUricx7j7xSZ+K6peA/nCDCbFxNRkvduqSz9zXPiPediv1CS8xMpGsPohOzJTz9IWUQGn3hexpKnF1I3x0PMzs+Gx2ZPHQcAtO+S/WecgwTkXheDl8A9PDw8mhQbLoGnWdQLGhcSRpoUivJvjXW/yEZFybGklFK/zLkcuwspBshJgs7dSnEW4CZU60p65unJKMmj6sgmvqzV0hR/TsS01M/XVySLYWk8YCKl0VBS6yqSm5P+ErG1Xd/G50QCSfCYO3LCQKYM3b+yKL/uLrItEidptWFVlCGTxrm2TWGbc4nL5kQ6S7HUHrDGE6gISCdRR5XLVqaVpL+uXslNH7DWs8gSU7ZDItE+PEiSY29XLmz79vc4wm1CJBoXCdrCuVu0m1iBpamUyvVSW4UADfvDe01rPGme+8CodXSbwLi9KeueZLI73VBuqSwZ19Vj5wi2gEXvxrLldzlwpCXtiESlsdYqREwn03TiqREhy86zG97dt0nUYMCags794VxPK0wA1pQm0JFjJ4FA5i/pNOFA+rEyWfRSTRGyrK2klHaac/OsiPUffYUk2W7OzZLoFc1hybnAKtdFW6V+1NTDXI3R53qN+tZQhKVTsKtK6nfR0jU9p1X6XFig56qhPCRc9HUyJXvy2t37AABBWca867pdAIC2FtJYf/CTn4TH5iYocWtuy46wLa7cDNcLL4F7eHh4NCn8C9zDw8OjSbHhJpQUm1C0D7eLaIyoVLDhZ07+ElOq7GCWhtEbF/2zjZMDhVGaAAIme4rsU1ypqmisBJkbdLTZNEePmZioRQ023SwVqR+LZVHnSg0mmLQqxOpZXBEpTpVuuMsuiyBdxYQClx5WpSFdcY4mX1n7w8S8KLWdHWT2uGXftWHbZlbf6hGao+5uSQ6V5iRS5Yr0x6nvVv3uO+LM+bYv88flPiVUBGkyQep4TPmB1/g78RSZbfIlWYP9z1CJ1WMj4hs+NEA+wr1dQqbOzZMa3srrXVfqsEstrPjVMIpyNbgEVDFlEjEcJxCFJmk5iVrUxQQI3DcTUWXCi7jIQH2mmxuaq0BFaTbcGNRej0WpzSryvMB2lyr7Ik+cfTk81sXz3Nolpghn9iuo9LozVepb2dAe037SUZfiVudc43vGokL0XgCVGjf0106oJFwZmr+pOSEDywtkFhvsoTUujojP9/GjFE0aU+bTOJOiRpl8Xg0u3COyLF3zhbEa1TLtp0qFnqGYIqgbfP6WLWJefOAjvwQAOHdE0h5PT9K46v30XBnV7xJHNednJKq0c3Db+gahx/Oav+Hh4eHhcVXgohK4MeZTAN4HYNJau4/bOgF8EcAwgBEAv2StnVvrGq+GNKfHDOqaxHR/pS0WRj7yL7+RX/dskqWXiiRHLzF51JZS0XF5Op5foL+a6Epw3o4WnbMk4ggMIQhb2ilPx2xA0k51ToYdgKS/pJb62fXOKu0gJFd4eFrTcJLK8lwX3EclNa6UwLvbRRqdmVvga8k9WzupqEEkKectFqgfB4+RlLvvDUJ69g+wFqH6neCcEuW8cntkN0JHvlYrMleO3IsnhLCMJ0nKjuroVk6WYtk1c14nemGpZWFWXbdB0su58+IWmGRX0qE+jjJURNfs1kEAwOh5SSdbLK2dsjPLZGdS5ddwKUn1ujg3xtVSEbtPOmIyTBus2lYS9lrCj7O2aSLSFvC+q1mt6dDf8hLt6/HjIgVev40LKKRkvi0Tj8siTfn5cxqUJuedwqDJwBq77TUqa9e5vePO28LPp0ao8EdNPV9zHO1ZXxASs8HPxqEpJ5nKGixyRGigI5LZnTit3F1T7ELqtIhaTbso02SlVZ6blhb6brEk8zHK+yN0VY3q55eO3aiiLoe30B5rq8k7qL6ZJO+vP0NR0pGEaCsVtgKMnToatnX2Surm9WI9Evg/AHjXirZPAHjUWrsLwKP8bw8PDw+PK4iLSuDW2seNMcMrmu8H8Bb+/BkAPwDwe5fSgSxLBkFd2wo5qEFL4FgujUR0kA9L4OWoJKhfYitkoSLnOaErXyVJs15Wku+s+7UW+6vLcVFWUmWGk9QbnrqCsoEnW2gsmaR2x6O/NpDxVdjOaVkDWFYAwl1O2/QCZ0uW5VLyKADg5r27ws9VjmiaW5SzlnjwtiYS08HDJKkdOzYCANilggpckvuUktwMS+BmWYJ8Ps5DqFTl+snUhfZuw+540bhI+26dE4kMH5N73s0aw7lzZ8K2Zx6ncnK5mExSa4bty0ymjJ6fCo91dZKE1dsjQUyl8toBKE7T0cUvoqEYqmzgEWcHXm4LB0QCNyozYD3M0SH3dgFIbm118Jq1LtuhltjZBVU9ubkczde5U2xLXpA12Pp24jmqcZVpj6XKzohKdMOa8Myi299yzzRrIg2lJaPCkqzSDqSUAeEDH3hf+Pmll14EABx68aWwrTRLmmJWlSbLs2vjsUlyhSypohDxFnLbS+dEiwzyNL+plIylr4dyALXnaN1jijvasoXKmu1U+VdaWui9ceDZA2Hb8weeASDcklGvSlfoY0YFl504SYE5XVFZ73KB+n7w+BH6t8p55IL9GmXRPsol93ltfmYlLtUG3metHQMA/tt7kfM9PDw8PF5n/MxJTGPMx40xB4wxB4rFte1lHh4eHh6vDZfqRjhhjBmw1o4ZYwYATK51orX2kwA+CQAD/T0X5E0VE4q0mdVqYjrTCauycWV2yCXJJNGakhwa0+z+Vte1JVucSspqmdKiI+w+lVIqYZqLTSRU51w9y4Crdsdb5PppJi9TKZ2jg8ZXUxGKjthyxJVOL2qYeLQqgs9xXnFF3qxkjH98QFzHenvIZbCnQ0xK+3aRyphIi3p26AiZJXYMk5rd3d0VHqtx3oloTogXV2dUp/51nxtMTmmiC+xW2VB1Mq0zH0SEdIpw9feoU+1VfcNYkuY00yrmj1dO0HaLK7PAnR2kNrewKaC8KFGai0W6ZzQl5HJbh4x1JVJJJidV6hlnJolo4s/1P+pqL8r5ziwULCMg6W90mWuh+3RhSmGnvgfLUi3z3lFadob3xdJpMmL0tUhBjGwnmRvKRl+DztdpatkChVgLp23WJGlAgldVtfW30xo16rI/VppQKnnJd3PrdUSmtigT5RNPU9X64XZZl6E4EX9Lecpfk2+XnDZ33/UmAMDh4yfDthNz9HmMIxsB4IbrqJL8W99P0acdPZJWucYy6/SMENoDA3T80cekrcxEpWUTV0S9KmNRMtccfEnI4hM7yaWw4w1iyjx0htweXzlGBG5CmXlguSCGmtNG6Av5szehPATgAf78AICvXeJ1PDw8PDwuEetxI/w8iLDsNsaMAvhDAH8K4EvGmI8BOAPgw5fagVSCxICGEl+c9BJRbU7icMJLi5JGJ4/SL+GR0VNy4RhJCC0qgCHP+RKWFuf43ipnCf+NKlefBAcTRJTLW5SvW6iQBJ5Ly7E6V9dOZdQvKJOXJpCxJDgDo3MrC3QGREd2rlKVPrpKeTiHqnKVOnmaCKDJGSmflsySdlIcl8CIGmdfS6VoLqNR6UeKidikEkNjLE1a5Z4YizmNgYnIpEgZSQ5oiurcMJx5sFoSdyuXMTKVYZdERdq1MnH1znf+XNj25S9+HgAwPSVSl0ttcuAgaRUj5yTnS0crSeWJumgCeVUdfSUceRmPXjjOuFGE7IrvaXe/kMTUZyVcOS9VZMQF8Lj11nthlWr3LneKVSx3tUBzOXOW5mN4h+TXiHF2xrSKdHG3qKhcKK7QRpzdNqMqoKjKEWdGEeAJV9AheqHm4PDsM8+Enwc6aW2LeSElp5hYT6m9vnUTuZx299Bz+753vCM8tmc3lQB8/Ac/CtvqnNNk/LzshYCl/Ot20zyUlYb7t5/+LADg7Dl5Dj70ofcDAA4eORS2heSlc2lW44ryHqioDIjd7KabUqUCwTmGEvxOqc8K6RnjeauofDHlgiMx119TbT1eKL+8xqG3r9Hu4eHh4XEF4CMxPTw8PJoUG54LpZVVvHpN+b/y34Typ7ZM3sSYUOxQ6mpXP5EQMyWh9jJcFCBQKv3hUxS5V8/T31SnqCrjY+Q3PD4lak6K00AmFakWZ//lrVt3LO8spN5fUvlON6p0QsSK2uzIOhu4Gp2i4gWBM0kopc1VpX+VmpjplEplyv7R24c3h211vsahk6fDtjynb03nKM+I/jVPs+lEpwxxRTcimpjjyD3XElN5Txp8z0JefF1dms50iyJ1o2TiiLO/rk776qIR914n1b7f816qXP7DR6Um4Y7tRH69dISoNJ2jZnKeCLFsRuavt11Sga5EgtVbnYrYWYH0HLnPbvkiqxGRqi0ev3D9XOSjm9NAk9dh5KbOw8FtKs/I1ASZgypFUul7dgyHx1zxiA4Vh7DEPS/pe/E94sblFhETiouydbEBAFBl1T/QeWdXIKHMkUeYeFxUsQn5Ml33pUkhD6cmXgAAJNmUsucaIQXTbMrUxSxcgY1kSvl6bxsGAEQ5v9EjD38zPPZPDxJdt2On5B3Js1mnqApQuPgGZ97TsQkxvmc8piKSXY4V9cBcfz2ZfN4xTuP7/INfD4/V2QRr1TwX5xzpu34TipfAPTw8PJoUGy6BnzlK0U86B8SmTeSS88xTz4Zt2/aQBDY8SPkCjHJR2redzm/dKdFVTrY4PS75Mg4/T/e693bK0WDT8qvdNUhSWu+cuJ9VmPQszAnh1uAoxzQTbUFSpIzsEJGe7cpdqMz5PWpxJe1wRJtZhcRs8G+qzg0TRmK+Sga9N+wVCbXM5Eq2RX7JxybJ9S5hhTRpYam9o53OiynS2HL2xJrKdeEEby1zVTmHTIPPrysytcJkdKUkEniEJfTIoqxfW4Wu2MsEWiopLoMuC1x3t7S9+z4itg49/3jYlmZtaetmkkx7OoVMmub1Gzkjmd/Oz0ifViLO4nZMk5isNUV1lfnAReldKHk798DgAqoTWO4yuFyCjSrtxrI7md4f7qPeCSc5ojbGUmh2QNzmxsZHAADppLjqxQa30jVUIsEkk/NJvnLUirtfhMdZVYRbhOdIl5FbCe2W2uDvZtplLMfH6ZlbqMmYF6tEvL+5azcAYOuQ5Adx5d6GBiVucGGRrmEVSetcN+e4eMmjj0khBcfbLszLMz0zTfeMKE0nyfMV7gHlQFDn8mr3vuktYdv2XTu4HzIWl2PlnrveCAB48sAL4bEjRyhyM5mRd4UrdvJa4CVwDw8PjyaFf4F7eHh4NCk23ISy/5EHAQC5hKgSExwl9+xTT8uJi28FAIywinLrjmvCQ4m+uwAAdVXn0LAvb2ta9MSdmynl4wAXN0h3iYoXZSKtRakxGS4wsP/xH4dtB16gqtP7dlNhhJ4+iXqrcCKb0ZelMrWrXN7aNxS2xVJ0/3pY6Vwl7XJmlagialgri0VWU8cJybiMs6eD+nTirMTGnWTyUqvojiDs4fmIKxOKqw+oXIWFpAsu9FF3inFcmRic2tyoKv9rJnOX6uKjPjZD6uzsLJHQO3aKH/PQIK2ZHnud/ZG3DMr6jbMP9MFjFP2WyUoUak83zcfwJknWtbi4djpZZyaJKPOHM4nYiCKu3DHnC69MI25N44GsS2hWUZG9rsSrK+QQVWRjgxe+VlNFEJh4rBXExHH8BUqW1MuEXy4npHtuks6vJ6TfLo1yTieLc7EXgYs5UPVAQWPQHHql4vqkStuvgCa0ewdp/3epqMijx0cAANPzYk6rsWlygB0TNvVLHIe703WK2Dx00Pluy55cLJCJ48n95Id+5JjEh0Rj9EwvKTL18R+RiaWoirkEXBvXRRjXGmJK3MR9e+tb3xS2tfEzVFOJ72pVV4uV9nxPr7wrjp+l993A9u1hW0uXmAnXCy+Be3h4eDQpNlwCb0wRmbTrBvlV3cIliHbeJyW+Yh0kGde48vzNe4S0c9KZKmyPIqdprKo8Env37gUAGCYZNeFWZxes2QkhusCSrE5an2OJvo8jy7b1ixT42FMkqY8eOhK2Rdi/KHHDzWFbC6dtLTvSxOoUouyWp4VtdqGMYG2XrbwID0hyJGhUVVXv7yPiZ3FBJN8Sk7SO7NEFLqJOmlSuZq48nNSCkxSqLueLVSkzA46Si6sCBi596nRRSMTzTDSfP03S8/i5kfDYnutozTZvGg7bDh2h81KtQsy9fIgS4zc450xhQVxKF7lMVzIt57vIudWgaURpc9qHanMFOVaJkHXnG30+X1mn+AlWIUDDu7OmE1MEXYaX6NyU7NM8R9ze6SIw86JddPMjbnUxBs5Nk4qLpB7lXCkuha1W9lzOHr0VnKQeX6UEoMOxkZHw8x133krnq+jnTZtJuj6uyqa5XECdneRGmExJLhTDhOKNt1wftj30CLnm1VVOkR/95AkA4h64WJKo3MCNBbLXDx3kogrKpc95MLdxcYiubnEIeOs9dwIAdm4TV0Tn5hzVEeX8TFSqtH6z0/PhsTrv05hKjdsIta+198RKeAncw8PDo0nhX+AeHh4eTYoNN6GMnyZ/yO+NS9XxllZSK/r6xQe0wiaC4S3kw/qt2UfCY71MUt166y1h24uHiNz40ue/KNfgFLDgiL9b33RneCydJVVpSlXZWGgnUqFFqXG7d5DaND46AgCYG5dKMWMnyB/3tmt3hm07mISbqojZ4cQJSv1aYHIoHhMCt43vqU0REuq39nIpzRSjnNhnTkVAZjndake3kEJFrssXMIFbLYmpqI/9qLUJIExruiwSzpGYTL6qtLkxV5VeV3fnhF+JmpA9s9M05y615sSEJJp64adECN9wk9RXdOr+zKyYg45wlG3AEYq5jPj4Z5Jc7cbKPcfLa+emd6aqmDKmOJPSshTH4fmSukrg5kXMdAGT7KWKrEu9rmxfAOrLLFZcgV4lkbJMCJ8/KYmX2nrIHNQ/QCbHekFMBpOnaH/WVerd9jiZAxIZRfozCe6qIjWU6THCFVgDNWcR9vs3dm11f3RczDzOSjg7L6atOFdsyqZl/9c5qVZ7FxN+ykTjzG9bt0q8R18fmVpOjwhh/8pL9Hy5IFGXJA0AYhxpWq/LunR20F7/wLulcuQwOzy08z7qaBVzU38vzXdGmeTcfNXUvMWZvKxxIruyegdU2Xy5sCBr1d26ftOJg5fAPTw8PJoUGy6B915DEm1hTlyJeofJtSbd1ha2lUdJSnvwS5TLoFgU6auPo/T++I/+MGxLc+3Fn/xYXBHnzxOZlWijX84tnKsAANpdrpD9Ei1V4zSXOmOmq33X2kmk6o03yTUSXBNTJ5fnJjz3ghRcsG0kBY+xRnD+vNTD2LmDyFwd8ZdfIDe7wf5BrIWS8vc7zJF59YaQMimWcuIqIq9vgK73c8NJYsgAACAASURBVHffDgC4pltFgrlIzLpcI8qS6TLSjkmb0OVNpQaNuVwvStoJmDhONlSkX82RqbQHjHLVGx8jaXxsXObo9puJxMqoWof97M45OUMS3vySSIvzS9S3pIpkdTl4VkMq4nK+KNKYK7nr2qZh6t/YhVKdi4bNLwhxNc9RvnNKCnV5cJxkv6S0oHKB5iOipPT6El3v2OFjYduuG8nF1ra56EE5f+s1RGyOz0hE8oEfUQRrsSL9zeboWcu00t+GWncb0N46dVIKKThpOKVyDa3EMlfEJEnB3/rmd8K2kVBqVnmC+I2U5ihpo6JhXcrd4U2S4+e976A0w489/kTYdmaUnz8WwWNKc3XzXFNaTVuWpOt33/fOsG33Tnbv47nX7oGOVLZKE7Uhoy1jqXDd1aorAqO0iRqTyjVVpUxcfD2J6eHh4fEvHhsugZtechPbc41I27dfT252eeUKtn/shwDEVl1Vv6ATU3TeuTGRMm688QYAQEaV0cobktpzGZI0BwY3hcfK82RbPHNUXJoWOFF+W05saKPH6HjPFrLPt7xdpIFsP43h8EkJHDhwgKpxd/TLvdJtbE9je2Nbn0iDMwX6ZTbaFhqQJDOdX7uS+qkRyTLopGBtngwT6atghXtuuwMA8IZeGt/8KXF/zHbS+KIqg57LShdRdnFXYb3K0r5LsM89p/+rHBouo2Gb2nm7e2gejnP+jZK6foY1h4kxWZfJGdIcEnHhJm7dR5pcJE4BVuOTktNmZJRssZNTsp8mZsX2uBJz51zmPJUvg0twFas6IIYLRXD2xEWV32WBpWxnPwbEHa9alXWssl08laSxLKocP9NsQ86ofCOLnNNmUfmNdrO0WGX30VxM5qWzlQJoDk3I/njh6ScBAEpBQ4x5HsvBNxOTU+GxAmdznJwULahYpOcloYqdvOcX3g+Nc+fEBv7wwyR5Hz0i/Siy6y4CGV97F+3FwSGy58fV9WslGnNSSdT33/ceAMD1+24K27745a8CAJ58mvMsqeegu5O09fyCNEb5YUuo7JPGLg9Qiijp2RXV0IFvzlZvoqIVRvh6ZeaFlsri3uncR+slWcdGGIj4OpZUM8ZsNsY8Zow5ZIx5xRjz29zeaYz5rjHmGP997WFEHh4eHh6XjPWYUOoAftdauwfAHQB+yxhzHYBPAHjUWrsLwKP8bw8PDw+PK4T1lFQbAzDGn5eMMYcADAG4H1QrEwA+A+AHAH7vtXYgmyazw2CfuLfdvHsYANCVFHe8u3aTinx69D4AwLHjx8NjJ06QyptWpg5Xa06reA4uMX1Xl+RlODFG0X06BK2D1a1KUdRtVxsxyxFU0YxEaNU5JWe5LirQ/CInvh9UaSNj1E8XdYYWcVGqseYWVXUnXYnIJVUUQgxDBKfSAkBSJd5fiWRGTFU37yUCNsaRptPzQgxnOBVtJCLqeIQZJqNyobgeJcPEICoXCkdsWkWIOdNQQhE1Qy00mjiHvx2fEuLvOY7S1DU/ZzjycHRK1uXZ58hU1d9Da7Z9ixC+b7qVTHJLyq1ydEJMLCvx7Pcpui+fl+svsHmkoUi7BBf6cMUYajqyl0mqlpzMn3M7yyalzbJJxqUoRV7WIMskWUKte4n3U0+PmOT6e3msrPbHVE3ROq/VzJzMqWEzV6tyj3VvApeLJK3IQ8smi/42yeVxrkBEoS2pZDkrkF+U+X56v0sNraNyeT9FZXx33UlmvX379qw4W6IXG8oE5Vx8Nw9IrqFd24m4ffGlgzQ0tWbDm2neqj3yHDSYRM+qvEnOOrKMtHb9qDszp4qgZtNJYDTBT72fZmLd/QUkPXFduWY2wv3zM6pKb4wZBnATgP0A+vjl7l7yvWt85+PGmAPGmAPF4tq+tx4eHh4erw3rJjGNMTkAXwbwO9baRfMqORA0rLWfBPBJABjo77nAPyYep9+QuSX5dTpxmiTqTlUa6trtQ/yXAnnue/Md4bFFdorX7m3PPf9T1/OwzRUHyOWIxIyrMkw79pH73m8O/oewrbOXfqVLeZFeZtitbZQJsWhCrp/j5OytA/Jbdk0rBwj1SNsSE0Vpl3kwIkSGK5sWVSXVLJOSukr6SkSVFOPIqeVhJXSvTEakrhb+XGHpz6r5S8Rd8IuSmPj3PqKyzDlFwZWGSuhAF0vn1ZUEWeNK5M41DQC6OQvbVv47PivVzJfYlU5Xdy8wudjXK7SLy4Fy/DiRnSdHJBgok6V12aIKAfT1rJ0LpVam+WjLiUTW2kLXKKt5buumIBJXwbxa1WQtS8NqEVyBkJoqcBFn6b3CkWoxlfWuhTWSukryUyjRvW7cJu6rrQnaz+USzUtWF/7g4JGZCSEgq0U6b2lWiMpsF48l4crbSceHBkk7XlwQUteVmHP9Xg26DJlzD9SurVVes4E+0WLfex+5BXZkScPVGUadVr2Yl3640mTzc6KBWo6G2rqV3hVVtQbt7HI80C15TBqcNTCnNGFXqq1Wo+uWlRbeYAm8oQug8EJXVMKYIudAOcPOFaWCrHuU35/1hmgTRhHe68W6JHBjTBz08v6ctfafuXnCGDPAxwcATK71fQ8PDw+P1x/r8UIxAP4ewCFr7Z+rQw8BeIA/PwDga69/9zw8PDw81sJ6TCh3A/gogJeMMc4u8d8A/CmALxljPgbgDIAPX1IPmGScr4hq9cQhMqHUVQb5rV2kJnYxcdSVExIix4lAIso/tMEpM+sq2ixwxRXYD3u7ShG5eYBJobKowa66fFbVrUuwKj86TernkjJ1jM1Q21Rd1LlcgvxZl5TfccUVQWA1NK3r7a1imnLmKp26c6UtyizLUeqqmavjrn6jrijPZo8Kq/6TU0Ls7dhJJJIuFFFn9TCm2mxY/IDXT6XeDVi91pafgNXORFKiPrs6SEXPM+F2UqUXrbJ629oi611hsqe1Q1JxDg2RCWCax1Aqy7rnl0h1ffbFo2FbnFN93nSTFHlw6N17L/U7IXNaqVM/WtRadXDemiTXRa0pcs3lizGqmMXSPPVtSfl6O7Oeq72YVPxzo85qeVH29VyR2rbulPTLhuc+V+UiEjV5lmY418bWHSp/SBdFbpYqQka39pCJ0pHzNeW7X2OTxKTyDU8yMRiPSYdfPiT5WVbC7TtddzLg+dp77e6wbfd2Mm0YJr4Xl8TsMDvD87ekniXeb8WSmB9aW+m53sFk5ryKonRxJFuHt4Zt7VzEJanq27pnp8rXr6l0vC6as6RymzR4jmaXZL1fPETRsgdeIII9npY9n+L4lEy3pMxOtzqSeG1ieCXW44XyY2DVyqwA8PZ138nDw8PD43XFhkdiOsnDqCrsC+yt8vJpidrq7qeE8BXOcTE2Je5WXe0kNXR1CKnVv4kiCe+4U7LYPfkkRWZ1tnMxhg6RwHs5M1qwitthsKxUG0lgZ46S2+F+/nUFgJtvp+rTN3AUKADkC/SLPF6TbGmFRZYuWLqEIvRirCXoMmtRdldqKOlvpe1r9xZxiVzK03UXlVRSYk3EKDeninPLCvsq0vMiS7BbOoTsK/FYdKa6KEtUjvOq6xwaTFg5kki3pVUi+zRHxh4/Sxkpz0yIpBew5rAsEo4l9VxKSKfdXMxgeBNJknOq6vjENEVRzqp8O4v5tUuq9e+8kcaWUtIia02xQOYvxmNPstisK7S7IiNBTSTIIkf2lsoiQUZ5/8eYeFTpQxBnjacwPh22HXuGsjOOP/+jsK1ymPP3sEuajak14CjX7gHRYDJDtD+jGXELrMboPKfZWRWJWOKcItmh4bDNrXOgs2aukMB1rhB3fkxJ7C63zvZh0Q5auRzc5DiR0IePiruw28M9fZKldOQcUW8nuTwbAJT5vFkXya2iiR3ZrXO99PUSua0dMxwxHSozSnNwrrIFVShirkCODgdUzqOHv/MYAGCc3V43X7MvPJbuoHtGVKR4or2HP8m74mLwuVA8PDw8mhT+Be7h4eHRpNhwE4pTqY2q3+jUsrNjokqfOke+lDdeS8mKjEqaNMvJdiZmVfVpjij7zf/0G2Hbz/88JduJMHnXoYhQ91O2nOTjdLIxUZudacOlOf3m178RHhvk4g03qKrZ6V76bl+7mGtmynT/GY70m5gSD8xZTqo1tyhmhyVW98tGTBcrIzF3bhYypMhz40wegJhHyqoWYM0l1+EkSIWyzOkrrLpuUak702nD5wkpFHCaVUei6qg69zmuIkPjXFgglZUR1KPUNsJzuqgCvlKc/lYFf4Y+6kvKtHWaozJd/c32FiGMtgwRSVpXqW7PnJPEZysRRB2xKCaa0AdemVAcad5wm0cdC1z9S7WvU21kuku0aH9fNkVwIYqKIkJNjca0NCFFRioTZGZ69uB3w7Z2XkYXgGnaVVX6PUTWpYYlMrV1gIjCvh1icox20Hfqrr5sIH10JrNGVJvfytzvtavS67gMw2aHhvJ73rqZzF233SL1Ys+OkAPD/ieovmwircbSQSaGV45IKt1HH6eK8qNnhfhOsP+8I4sTKhKzu5Oew22bxQzT2dXFfZS+u3dQmfdYQT1LSWduVebIk6dpXR559LGw7ehxjmfhRHYDW6UCfbKT1sMqhr/UWHsu14KXwD08PDyaFBsugbtf91hE+U9xXgFdaXr/firMEOHz9a92J5OYuhr3ElciD1NWAhjexq6CTFCMjEu0nmGpSxN0LrJuWYF4/tXduZfcz379NyRys42l7DNnhIRw3y2qMleWWzviJBmk05LDJcdSXEy5P5YXaB4Kr/IDndWuiDy+pCpakGOXyECxZPl5SvdZSRCZ1dUhGsm5M0QgHx+RJP572XUtptytXKBm4AirQIjCIrsRJnXuDy56kEyqfrDL5/kpIuvqOtcKaz8NRZbFmGjOqdw387O03gWe57xyNXMpXQcHJN/O8FZxI1uJaILWxRhFuDGJpYJQVb4MJmtV9XinMsTVWKpc5EGTmE4idfujqiL+EnXaf4Ul2cODO0gD7ekWibqfpVTnKhooMrXC615SwZm1OSJTjSoeke5ijYHH1NClzFy0rZVnwzpXt6ga8wroVLAuX0xU5db5tV/9FQBAX68Q8D94hDTa/h7ak0PDO8Jjj/1kPwDgOz98Kmw7O85aupp7F0XpCkAYK5HUFY6CzWZEsnefjcrj4579yRm3r2QNcky0ZnOi5Z0+S8/88RNiBXBL794tUG7RbvMYlTdal0VcL7wE7uHh4dGk8C9wDw8PjybFhptQwCaJUklUFJcWM6Iqeh9/hYJAz75IvtzzZySG6B333AMA2KIqrnfliCCpKRW2wuq7I4p0Ctaz58iccuK8kCFLTp1VkW0LXOklyr99ViVqOvIyVbQpLIkPcoNNFmWVdnPJRZSxr7LO0phnn/A+FSnWMUh+sskW8dsVL2pCLiuqaYxrORZUhfiIq+OnyKm5OSLy5jJkEunr6gmPzXP61Jdf/mnY5lTdwT4hNg1voQaTmToaMUi5KvbS1mDzkY4cjbD5LME+sc4vFwDynAK2qiID+/upn33KH9glj5qaoDHpyDnnk3305JmwbWKBzDs3XX8NVsIZD6I63tWRtVE1Pp5LR3ZblfirxCp3vKR8smvOF1/asmxKCrnOhOzXBs9R0CMEdUeKiMdAz1+W1iDBt4+oqOYWjhAcHx0J22p5SgVbXBD/8jKr9DUm1XR9TxeNG1UmlJSl9Uil1tb7q2r/RS3t8Q9/+BfCtve/m2pQfuNrD4dtlufy1tspfuNbj0mty0999h+pryr62ZlbtXnHVdhxieEa6h2Q4/qXQ5sk/azz/9axBi598Tn2wU+rpHWDg7T/IgkxJZ48RXurosxSxvm8hyYUWbN6lfZHoKvYO5J47XKtF8BL4B4eHh5Nig2XwF3OhbpK2Wpq9OvUUGSP4c+LnE/iH//mr8Jjz33nEQDA2+99S9h2551vBgD0Dij3qTDakv62KRIiw0So6RL3tjS7H+VPSZX55/hzjaV3zVu1srRdV5JHkU+oKmm/wilVwb++1ZIcK3F+1nhW3A5jLDXYV3HZ2rFT0mMWiiS1Ts1KtOrsPEnU5Yrcq+aiIjnisCMnxM7wlj6+pwxwZpJIz/YWic5MptwcktSja2halzJTRb0l0qQpNNTWSzKZu2sLuVmNTokGM5Wi9c6mRdbYsY3OS+WkH2+99y4AwLFDpKWMT4vrnUukX1CEdn5WpM+VaHDujHJDFXTgGpcJxTQlkssLZ+TU/IWjU653LpVvPKEjPGkPRFgSt8r9scLSs5aoU900p/NqP53nZyfFEp7KGIwUE3mZLaI1pcqcRljVFF1apDFPzNC81VVOm15Om+tyCAFAOsMqQ2xtGTCtXEXv42fzg++/L2yb43S250ZF673lRqqRO7dAY3r4W98Oj5VYKo4mpN8N1np0LyKsQ7moZqu0lZ0csduporZdgQbNIjrS/MwokZPDg7LXtrD74/Gz4qzg3Agjigh1z4IrNGNUel2nEQfKdbDiNHHh5i8KL4F7eHh4NCk2XAJvFEhKXJqRCtaVJZK6Ysp2muKE+j19XGZNlSKaHqPvfurTnwrbHvkK2dVuv0MKP9x5z5sAALs4+1lSSeBptpO2qF/Q0WMUzFKZlGITWU7cPsrSaFVJlxkOCJgviDZR4srzNZVXI95BP7ENdj+LKCm3LUOaQDYt0osNbaxrS+CpiNiIUy1sU47KT3lLmqSLWkPaLEv7hqWo7iGxKXewS2G1KLk8amwXzRdEsnfRD87uGFH23RhLhA1VyT0W42rcKv+LYXe5nVwIw94gduljXIigrUs0ko5O6me0TbkFXns7AGBslCShm3qFJWhtp4rlM3MiUZ8+Jy6kK1HnAKcFVfDA2dFzrTJHOS475+z5uqhGwAFLBZWXpMDrV1OVyMscFOUyQxYC2X81lp5LSmuq1+m7Vtl1O5Is4fEaRCOiAdaDMv9VtvUorW0ko6RQzmSYjtC14iqgrcwSaiEv/a6zxF5vyP5YiZx6vu6++24AQJ8qnfjjH5E7YEUFkO3aRa6qx04cBgCM8noCQJx9OAPFNTjNT/MPWJHRM6kCeYY2kStxSb0/3DUiykZdZq34/DmSsq/dISXs4ixJHzkq2S2npzmTp/IzjbGmkOPsiAkV0BYGlengIbu2S+Za8BK4h4eHR5PCv8A9PDw8mhQXNaEYY1IAHgc5t8QAPGit/UNjzDYAXwDQCeA5AB+11q4/EznDEW5xRX5FM2Q+iCk1O8NFFZJcxzLZKoRKVy+ZLqyqSVjnCuvff+L7Ydtjj38PAHDdNWRCuefNbwmPXXfjLXRdlV9j5AxFIQ5uFvVpey9FgGa7iSybV2lLnVLWomoposiuZmW5btqZJ9hFTkeAldkNaWZSSLYUq7CO7FsNVuWYcOpkUuVZaGNXwapK7ercqyqc8nSuJGMZ6qDxNVTUZTlw35N5rpZIdUwxARRXEbUuQb7Kex+63ml1tVIlgtW5fd2ye2d4bOswkW/jDVWHM0Fqvk7FmexmV8s+IsFeUOlWURsBAPR0SqTp4KvUxESMVN/OvmG5PhPfiaQiIKPL5R+7jEljN1PltukKbSRUatJElNO48tzGlBpdZpfMKMQMM8t1FcuK+O5spXvlmFCOKdKuEdC9pgoSIdvgHC41te9q/PxF22heiqogxnxtgfsjQynkaVzFkvR3Jfe2pNxpJyfJFBZTUaLj4+TyqXMNpZnkdpGQus5ow5kdoq9N7kwrVtftscVF6ZukLJbrznN+Jeci6vIcAUJ6PvWkRITm2Q16We4bJi9d6mSVikcivlVjLCQ511/8fT0zUQHwNmvtDQBuBPAuY8wdAP4HgL+w1u4CMAfgY+u+q4eHh4fHZWM9FXksAMf+xPk/C+BtAH6F2z8D4L8D+OvX2gGXW6SlTQiVFJfKsjVx+4o7Ao/JnqqSbAKW/hIZkcja+4k46BiWIIjF8yQFHDlJATcvviBBKt1d9AtbVzk3avwrWVfBKXN5Jp34l7ZeUVnbnISqpAwXnBJTLlUd/UzkMFG0UBTpqMpLUlNloKJlkv4imsNc4exfr6vk+dzvigpACjPKqYCYOmctdC5jJ46rwgvDpKVsHRL3RLA7W1WVCas26BoJznFhdMksltRjihArsfubSkWBOEu8htPpxZUU09vDcp0V7aPKou7Y6YNhW4bLg911NwV19Q9JkYDnnnmc/h54MmyrcXGFN+yTzJEOLslcPJFSbdSnhiJpXfCSY6KiKjudK7sVV+S14Tw3EbXHTIM0FudOFrVC6LkSeomI7J0oS4nnVR6fSoPmOcOSaaC0oCg/G22SbgRznAVzUe3rJe5TpUZ/FxZljedYKywrsnFpgY4vqZJnUsaE+6+KN7Swe2SgyNTZWXJZ1NJwhcnFXbtIC7vvPnE7fOTRHwIAGlCunFzUw6qAmBrvT5dZtFKRfp/mIjFvY7dTQJ4XTSI6otQRsfWaCkZjxwVdgi2TZTdktXd7+ujdk+L3ks40CbiXhdLQGpqcXR/WW5U+yvUwJwF8F8AJAPNWwp9GAQyt8d2PG2MOGGMO6IhDDw8PD4/Lw7pe4NbahrX2RgCbANwGYM9qp63x3U9aa2+11t6ayaxtw/Xw8PDweG14TX7g1tp5Y8wPANwBoN0YE2MpfBOA86/65TWQnyB/6o4hycMR58IB5UAk9laOnKoxqTG/IBXUweYDxUFghnNd5FLyo9G+hZSEDJNZS9Pir33yMKlWE5MSwZdlEkITEy5nfzLJaV/TcizOeRliyt8zkuY2FYVVyZNfeYUJqXhS+Q9zHpOGigKsl5kQU9FxK00oVg0+wr6oOkq0zvNWVInpXRrUVCbG95ZrjM2QD3RO1cTMsGoeKPNOwBGELsgxFhcTg3PHtcpXvsppU4OqXKOtg/T7KJO0VWU6i3Lei60qP8oEF704syR+2pkKqeHJBhHPe9tla/feTilYB9JiPjo5IvVWV8KwH7VVZFJYuED5aUsNRU7jqswDYW3JZbU82WdZJ+5nu1vAxFhD5fRwKr1VKUcjbBKJqFStBZdjhSOAl7lJs8nHKlltvkZzM54vqDb28efcLQsLsk8Wym7vyLoszhGx6dL4AsANYq0EAAx1ii9+wMUVFiekeElXOz2HLxyWOpIvHiOz2DVbhwEAd991Z3hshH2ydQ6jBPtaV5QposJxBZbnW6eIPjZCtWxPjUhenPYWMnH0tip/8W7qeypC75GpcYkW3b2DzHP/5v73hW3D2yh24duPPh62FXnvFjjqt6acviPO/KZMms5kiyEhTC+Gi0rgxpgeY0w7f04DeAeAQwAeA/AhPu0BAF9b9109PDw8PC4b65HABwB8xhDbGAHwJWvt140xBwF8wRjzxwCeB/D3l9KBCrvfnD8rv4jJJOcDiYoosTBFknGVo+T6B0Qic6fl5yVCMMJEV6Ds7kGaxNYMSy+tPUKcbmaxpbVfIv5CXlAVSwi40EKFpZdIXB1j6amooherSywFaJKxSNdwEYo15boIV+FcEX8x43I7rP17G1cudQ0n4dU0scmuUnFV3oxJmCS7bqVS4m5VY2JMSx5bBjfzvUT6i8ZdNjj6dxCRNQvCqvQyH6ZR4uvLecVFGl+KiaCoEbInE6E+xpSr2fmzJGXbmqytI/dCCVWR3AMt1I+he6Qq+PwNRM7OC78VwhUrWMYpuQFalc+CyTSRvBU5yec3jHbpcxKhrtZe5/ODZX8B0YiqSmIvu+MqD0uetaqCi47UxVFYc4ipvi0U6fPYnEiyM0zGF9jddWFepO35PK3H0oI8X4U5eh7zc6LFon95bpiK2n/f/T65dZ5XpezGOd/JopJMv/RtKhXXEaP9PKd8Fxs8rnha9oIbVVzn1uHo54AXcBk5yXvma1/9slyjRJlN+7J3y704QvaeN14PACipLIOnT5ATRFztj73bSWp+9mnZH4dPkcYQ5Ek7dJHPAJBwJQjV81IP+7l+CXw9XigvArhplfaTIHu4h4eHh8cGwEdienh4eDQpNjyZVYyZNh1l6KrGB0rVjLg6d0yITatIxQzXfowqwmh+ltSWmiL+khxFNzhIbItO/9mI0fXLgejUpWKF76l8w1ldrTufWG1eYRVJnY4IF3yoV3XNPvrdjHGkZEP9jLooyooijFJcM9O+SrKbaEL5CvP8lZVpJu3q/kWEWIow2ZpiddwEilzjBFdxVbsyzVGwOZVECjGee07kFFP1L11RhXiLSqBVKy07nzrC88GFA1w0HgAk2A/3vDLlTI1RVfKgLEnGYux/XuE9U1H++ZbXKJmS9XbRsvMVRYYznFkjCFSmoZiLrJS2wDjykverqkrvomtrSm12qU9rqlhCmUks53cc1C48NqdIu2lX81Ptj/ETlPAp3kpkcKxdnL4j3N+kYjYXFukaE9Myf+PsG15is0d+QZ6buWk6VpgXc0mZ0zpXtDPBzRJBCwC37JN6lq4YxOK8kJgJfl5v2iXV2uM8b1F+iHrU82VXJKkCxHy17BllM6fbRxFFzifi/Iwqs169ROMaPSv1LFs5bmOoj+by4EGJOTh2kMxHuijJEhds2TEocz/QTSbaOpvaykV5t4yeJ1PSvHpXpJWjw3rhJXAPDw+PJoVZlobxZ4yB/h77sY/+4hW7n4eHh8e/BPzJn/3ts9baW1e2ewncw8PDo0nhX+AeHh4eTQr/Avfw8PBoUvgXuIeHh0eT4oqSmMaYKQAFAGuXBG8OdKO5x9Ds/QeafwzN3n+g+cfQTP3faq3tWdl4RV/gAGCMObAam9pMaPYxNHv/geYfQ7P3H2j+MTR7/wFvQvHw8PBoWvgXuIeHh0eTYiNe4J/cgHu+3mj2MTR7/4HmH0Oz9x9o/jE0e/+vvA3cw8PDw+P1gTeheHh4eDQprugL3BjzLmPMEWPMcWPMJ67kvS8FxpjNxpjHjDGHjDGvGGN+m9s7jTHfNcYc478dF7vWRoKLUj9vjPk6/3ubMWY/9/+LxpjExa6xkTDGGUQq4gAABDxJREFUtBtjHjTGHOa1uLMJ1+C/8B562RjzeWNM6mpeB2PMp4wxk8aYl1XbqnNuCP+Hn+sXjTE3b1zPBWuM4X/yPnrRGPMVV22Mj/0+j+GIMea+jen1a8MVe4FzRZ+/BPBuANcB+GVjzHVX6v6XiDqA37XW7gHVAf0t7vMnADxqrd0F4FH+99WM3waVwXP4HwD+gvs/B+BjG9Kr9eN/A/i2tfZaADeAxtI0a2CMGQLwnwHcaq3dByAK4CO4utfhHwC8a0XbWnP+bgC7+L+PA/jrK9THi+EfcOEYvgtgn7X2egBHAfw+APBz/REAe/k7f8XvrKsaV1ICvw3AcWvtSWttFcAXANx/Be//mmGtHbPWPsefl0AvjiFQvz/Dp30GwAc3pocXhzFmE4D3Avg7/rcB8DYAD/IpV3v/WwG8GVyyz1pbtdbOo4nWgBEDkDbGxABkAIzhKl4Ha+3jAFYmS19rzu8H8H8t4SlQwfOBK9PTtbHaGKy13+FC7ADwFKggO0Bj+IK1tmKtPQXgOJqg4tiVfIEPATir/j3KbU0BY8wwqLTcfgB91toxgF7yAHrX/uaG438B+K8AXDWILgDzahNf7euwHcAUgE+zGejvjDFZNNEaWGvPAfgzAGdAL+4FAM+iudYBWHvOm/XZ/ncAvsWfm3IMV/IFfmE5DV0F9iqGMSYH4MsAfsdau7jR/VkvjDHvAzBprX1WN69y6tW8DjEANwP4a2vtTaBUDFetuWQ1sK34fgDbQBVrsyCzw0pczevwami2PQVjzB+ATKSfc02rnHZVjwG4si/wUQCb1b83ATh/Be9/STDGxEEv789Za/+Zmyecish/J9f6/gbjbgAfMMaMgExWbwNJ5O2sygNX/zqMAhi11u7nfz8IeqE3yxoAwDsAnLLWTllrawD+GcBdaK51ANae86Z6to0xDwB4H4BfteJH3VRjcLiSL/BnAOxi5j0BIgweuoL3f81ge/HfAzhkrf1zdeghAA/w5wcAfO1K9209sNb+vrV2k7V2GDTf37fW/iqAxwB8iE+7avsPANbacQBnjTG7uentAA6iSdaAcQbAHcaYDO8pN4amWQfGWnP+EIBfY2+UOwAsOFPL1QZjzLsA/B6AD1hri+rQQwA+YoxJGmO2gQjZpzeij68J1tor9h+A94CY3xMA/uBK3vsS+/smkBr1IoCf8n/vAdmRHwVwjP92bnRf1zGWtwD4On/eDtqcxwH8E4DkRvfvIn2/EcABXoevAuhotjUA8EcADgN4GcBnASSv5nUA8HmQvb4Gkk4/ttacg8wPf8nP9Usgb5urdQzHQbZu9zz/jTr/D3gMRwC8e6P7v57/fCSmh4eHR5PCR2J6eHh4NCn8C9zDw8OjSeFf4B4eHh5NCv8C9/Dw8GhS+Be4h4eHR5PCv8A9PDw8mhT+Be7h4eHRpPAvcA8PD48mxf8HuaMBoaTh5tUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " #===================================================== Import libraries ================================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn \n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from models.VGG16_with_flex_v10 import *\n",
    "\n",
    "\n",
    "# =================================================== Prepare the dataset ===============================================================================\n",
    "\n",
    "mean_cifar10 = [0.485, 0.456, 0.406]  # Mean and Std value hase been taken from a github implmentation online.\n",
    "std_cifar10 = [0.229, 0.224, 0.225]\n",
    "batch_size = 100\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../FlexibleCNNs/data', train=True, download= True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../FlexibleCNNs/data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # 10 Classes of the cifar-10\n",
    "\n",
    "# ========================================== Visualising the dataset ==========================================================================\n",
    "std= torch.FloatTensor(std_cifar10)\n",
    "mean = torch.FloatTensor(mean_cifar10)\n",
    "mean = mean[:,None,None]\n",
    "std = std[:,None,None]\n",
    "def imshow(img):\n",
    "    print(img.size())\n",
    "    img = img*std + mean     # unnormalize\n",
    "    \n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19,241,246 total parameters.\n",
      "19,241,246 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================== Model initialisation, Loss function and Optimizer =====================================\n",
    "model = VGG16()\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.001,momentum = 0.9,weight_decay = 0.006)\n",
    "schedule = torch.optim.lr_scheduler.StepLR(optimizer,step_size=20,gamma = 0.7)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} trainable parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): FlexiLayer1(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): Dropout2d(p=0.3, inplace=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): FlexiLayer2(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): Dropout2d(p=0.4, inplace=False)\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): FlexiLayer3(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (10): Dropout2d(p=0.4, inplace=False)\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): FlexiLayer4_2(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (10): Dropout2d(p=0.4, inplace=False)\n",
       "  )\n",
       "  (block5): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Dropout2d(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0   Loss:  1095.6112341880798   Train Accuracy : 16.246\n",
      "\n",
      "\n",
      "Test accuracy: 12 %\n",
      "Epoch:  1   Loss:  993.1688697338104   Train Accuracy : 21.75\n",
      "\n",
      "\n",
      "Test accuracy: 18 %\n",
      "Epoch:  2   Loss:  936.6700639724731   Train Accuracy : 26.97\n",
      "\n",
      "\n",
      "Test accuracy: 25 %\n",
      "Epoch:  3   Loss:  890.0105053186417   Train Accuracy : 31.114\n",
      "\n",
      "\n",
      "Test accuracy: 29 %\n",
      "Epoch:  4   Loss:  855.8779919147491   Train Accuracy : 34.192\n",
      "\n",
      "\n",
      "Test accuracy: 35 %\n",
      "Epoch:  5   Loss:  824.8954125642776   Train Accuracy : 37.518\n",
      "\n",
      "\n",
      "Test accuracy: 38 %\n",
      "Epoch:  6   Loss:  796.7768676280975   Train Accuracy : 40.13\n",
      "\n",
      "\n",
      "Test accuracy: 40 %\n",
      "Epoch:  7   Loss:  768.2594484090805   Train Accuracy : 42.904\n",
      "\n",
      "\n",
      "Test accuracy: 45 %\n",
      "Epoch:  8   Loss:  741.8495017290115   Train Accuracy : 44.806\n",
      "\n",
      "\n",
      "Test accuracy: 46 %\n",
      "Epoch:  9   Loss:  714.3723510503769   Train Accuracy : 47.698\n",
      "\n",
      "\n",
      "Test accuracy: 54 %\n",
      "Epoch:  10   Loss:  685.071456193924   Train Accuracy : 51.028\n",
      "\n",
      "\n",
      "Test accuracy: 55 %\n",
      "Epoch:  11   Loss:  659.7954469919205   Train Accuracy : 53.726\n",
      "\n",
      "\n",
      "Test accuracy: 58 %\n",
      "Epoch:  12   Loss:  636.5149585008621   Train Accuracy : 56.122\n",
      "\n",
      "\n",
      "Test accuracy: 59 %\n",
      "Epoch:  13   Loss:  610.7613677382469   Train Accuracy : 59.016\n",
      "\n",
      "\n",
      "Test accuracy: 62 %\n",
      "Epoch:  14   Loss:  589.3374382853508   Train Accuracy : 60.93\n",
      "\n",
      "\n",
      "Test accuracy: 65 %\n",
      "Epoch:  15   Loss:  570.8258588910103   Train Accuracy : 62.542\n",
      "\n",
      "\n",
      "Test accuracy: 68 %\n",
      "Epoch:  16   Loss:  553.0252484679222   Train Accuracy : 64.284\n",
      "\n",
      "\n",
      "Test accuracy: 68 %\n",
      "Epoch:  17   Loss:  537.8238874673843   Train Accuracy : 65.26\n",
      "\n",
      "\n",
      "Test accuracy: 71 %\n",
      "Epoch:  18   Loss:  521.2936589717865   Train Accuracy : 66.72\n",
      "\n",
      "\n",
      "Test accuracy: 70 %\n",
      "Epoch:  19   Loss:  504.6473267674446   Train Accuracy : 67.976\n",
      "\n",
      "\n",
      "Test accuracy: 73 %\n",
      "Epoch:  20   Loss:  482.9021812081337   Train Accuracy : 69.85\n",
      "\n",
      "\n",
      "Test accuracy: 74 %\n",
      "Epoch:  21   Loss:  469.7830511331558   Train Accuracy : 70.718\n",
      "\n",
      "\n",
      "Test accuracy: 75 %\n",
      "Epoch:  22   Loss:  458.30586326122284   Train Accuracy : 71.76\n",
      "\n",
      "\n",
      "Test accuracy: 75 %\n",
      "Epoch:  23   Loss:  451.5199730992317   Train Accuracy : 72.098\n",
      "\n",
      "\n",
      "Test accuracy: 77 %\n",
      "Epoch:  24   Loss:  436.9856027364731   Train Accuracy : 73.374\n",
      "\n",
      "\n",
      "Test accuracy: 77 %\n",
      "Epoch:  25   Loss:  433.2488965392113   Train Accuracy : 73.838\n",
      "\n",
      "\n",
      "Test accuracy: 78 %\n",
      "Epoch:  26   Loss:  420.1387534737587   Train Accuracy : 74.916\n",
      "\n",
      "\n",
      "Test accuracy: 78 %\n",
      "Epoch:  27   Loss:  415.05808556079865   Train Accuracy : 75.278\n",
      "\n",
      "\n",
      "Test accuracy: 79 %\n",
      "Epoch:  28   Loss:  407.8972792625427   Train Accuracy : 76.098\n",
      "\n",
      "\n",
      "Test accuracy: 78 %\n",
      "Epoch:  29   Loss:  401.3888957500458   Train Accuracy : 76.236\n",
      "\n",
      "\n",
      "Test accuracy: 79 %\n",
      "Epoch:  30   Loss:  390.7046746313572   Train Accuracy : 77.22\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  31   Loss:  388.7264868617058   Train Accuracy : 77.594\n",
      "\n",
      "\n",
      "Test accuracy: 80 %\n",
      "Epoch:  32   Loss:  382.75680899620056   Train Accuracy : 78.122\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  33   Loss:  372.6923660635948   Train Accuracy : 78.476\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  34   Loss:  366.1772274374962   Train Accuracy : 79.064\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  35   Loss:  364.80832132697105   Train Accuracy : 79.158\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  36   Loss:  357.1992036700249   Train Accuracy : 79.574\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  37   Loss:  354.1479068994522   Train Accuracy : 80.024\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  38   Loss:  343.141037106514   Train Accuracy : 80.658\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  39   Loss:  342.6252274811268   Train Accuracy : 80.96\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  40   Loss:  323.44775971770287   Train Accuracy : 82.256\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  41   Loss:  314.64921376109123   Train Accuracy : 82.812\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  42   Loss:  310.8797379434109   Train Accuracy : 83.198\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  43   Loss:  308.906311661005   Train Accuracy : 83.328\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  44   Loss:  302.7535830438137   Train Accuracy : 83.68\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  45   Loss:  295.4279252588749   Train Accuracy : 84.01\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  46   Loss:  296.7433778345585   Train Accuracy : 84.184\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  47   Loss:  293.73408365249634   Train Accuracy : 84.23\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  48   Loss:  288.18248039484024   Train Accuracy : 84.792\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  49   Loss:  282.89527902007103   Train Accuracy : 85.006\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  50   Loss:  282.7404842674732   Train Accuracy : 85.112\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  51   Loss:  281.7517393529415   Train Accuracy : 85.066\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  52   Loss:  275.50510969758034   Train Accuracy : 85.58\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  53   Loss:  273.2478488087654   Train Accuracy : 85.64\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  54   Loss:  271.9095809161663   Train Accuracy : 85.648\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  55   Loss:  267.53165712952614   Train Accuracy : 85.95\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  56   Loss:  264.54753336310387   Train Accuracy : 86.296\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  57   Loss:  261.6259790956974   Train Accuracy : 86.51\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  58   Loss:  259.53814148902893   Train Accuracy : 86.696\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  59   Loss:  256.41392755508423   Train Accuracy : 86.69\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  60   Loss:  245.23573705554008   Train Accuracy : 87.602\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  61   Loss:  233.9567729830742   Train Accuracy : 88.466\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  62   Loss:  231.75287744402885   Train Accuracy : 88.664\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  63   Loss:  225.79928793013096   Train Accuracy : 88.888\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  64   Loss:  225.93366211652756   Train Accuracy : 88.896\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  65   Loss:  224.60819298028946   Train Accuracy : 89.01\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  66   Loss:  222.0200074017048   Train Accuracy : 89.184\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  67   Loss:  223.16950149834156   Train Accuracy : 89.086\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  68   Loss:  214.9828395843506   Train Accuracy : 89.454\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  69   Loss:  214.31663036346436   Train Accuracy : 89.478\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  70   Loss:  214.38234296441078   Train Accuracy : 89.72\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  71   Loss:  209.72714352607727   Train Accuracy : 89.996\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  72   Loss:  208.435194298625   Train Accuracy : 89.942\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  73   Loss:  208.9794261455536   Train Accuracy : 89.876\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  74   Loss:  206.01220421493053   Train Accuracy : 90.026\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  75   Loss:  202.58217690885067   Train Accuracy : 90.214\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  76   Loss:  203.90573947131634   Train Accuracy : 90.338\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  77   Loss:  201.83090589940548   Train Accuracy : 90.372\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  78   Loss:  203.47567908465862   Train Accuracy : 90.388\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  79   Loss:  197.14005364477634   Train Accuracy : 90.676\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  80   Loss:  186.07515661418438   Train Accuracy : 91.44\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  81   Loss:  182.63029991090298   Train Accuracy : 91.6\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  82   Loss:  179.0516760647297   Train Accuracy : 91.8\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  83   Loss:  173.56804186105728   Train Accuracy : 92.204\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  84   Loss:  172.4323439747095   Train Accuracy : 92.282\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  85   Loss:  169.29610443115234   Train Accuracy : 92.514\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  86   Loss:  170.058188483119   Train Accuracy : 92.402\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  87   Loss:  169.11328093707561   Train Accuracy : 92.544\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  88   Loss:  168.16316625475883   Train Accuracy : 92.398\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  89   Loss:  165.77282662689686   Train Accuracy : 92.724\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  90   Loss:  164.50927893817425   Train Accuracy : 92.816\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  91   Loss:  161.80151091516018   Train Accuracy : 92.844\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  92   Loss:  162.03422632813454   Train Accuracy : 92.712\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  93   Loss:  159.7217833250761   Train Accuracy : 93.27\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  94   Loss:  156.93928189575672   Train Accuracy : 93.236\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  95   Loss:  157.0684554874897   Train Accuracy : 93.17\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 88 %\n",
      "Epoch:  96   Loss:  156.03850202262402   Train Accuracy : 93.32\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  97   Loss:  153.50333127379417   Train Accuracy : 93.462\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  98   Loss:  154.8093753606081   Train Accuracy : 93.344\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  99   Loss:  154.92706130445004   Train Accuracy : 93.388\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  100   Loss:  143.56019409000874   Train Accuracy : 94.24\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  101   Loss:  137.45578737556934   Train Accuracy : 94.448\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  102   Loss:  138.1751198619604   Train Accuracy : 94.502\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  103   Loss:  135.3607683032751   Train Accuracy : 94.52\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  104   Loss:  132.98166920244694   Train Accuracy : 94.8\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  105   Loss:  129.85061252117157   Train Accuracy : 94.924\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  106   Loss:  128.6549230515957   Train Accuracy : 95.092\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  107   Loss:  127.13767635822296   Train Accuracy : 95.058\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  108   Loss:  129.310565456748   Train Accuracy : 94.968\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  109   Loss:  126.75326842069626   Train Accuracy : 95.156\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  110   Loss:  125.25204107165337   Train Accuracy : 95.112\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  111   Loss:  123.39738880097866   Train Accuracy : 95.274\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  112   Loss:  122.2190852984786   Train Accuracy : 95.418\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  113   Loss:  121.78579881042242   Train Accuracy : 95.386\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  114   Loss:  121.61998447030783   Train Accuracy : 95.39\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  115   Loss:  120.61521561443806   Train Accuracy : 95.496\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  116   Loss:  121.85469906777143   Train Accuracy : 95.392\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  117   Loss:  118.10690955072641   Train Accuracy : 95.624\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  118   Loss:  118.4128330051899   Train Accuracy : 95.616\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  119   Loss:  118.22911174595356   Train Accuracy : 95.614\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  120   Loss:  111.78076306730509   Train Accuracy : 95.976\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  121   Loss:  107.38180682063103   Train Accuracy : 96.262\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  122   Loss:  107.58953049778938   Train Accuracy : 96.27\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  123   Loss:  106.25719681382179   Train Accuracy : 96.36\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  124   Loss:  103.58321338891983   Train Accuracy : 96.474\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  125   Loss:  103.92365576326847   Train Accuracy : 96.574\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  126   Loss:  101.76741401851177   Train Accuracy : 96.67\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  127   Loss:  100.88526376336813   Train Accuracy : 96.682\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  128   Loss:  100.31885375827551   Train Accuracy : 96.814\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  129   Loss:  99.33459398150444   Train Accuracy : 96.886\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  130   Loss:  98.33513931930065   Train Accuracy : 96.792\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  131   Loss:  98.0903208553791   Train Accuracy : 96.804\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  132   Loss:  97.53755885362625   Train Accuracy : 96.884\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  133   Loss:  98.0674761980772   Train Accuracy : 96.892\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  134   Loss:  95.54435628652573   Train Accuracy : 97.022\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  135   Loss:  97.49001652002335   Train Accuracy : 96.862\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  136   Loss:  95.72225016355515   Train Accuracy : 96.968\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  137   Loss:  95.60023468732834   Train Accuracy : 97.064\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  138   Loss:  94.43073026835918   Train Accuracy : 97.066\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  139   Loss:  96.71197959035635   Train Accuracy : 96.92\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  140   Loss:  89.87646698951721   Train Accuracy : 97.384\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  141   Loss:  87.17843940854073   Train Accuracy : 97.522\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  142   Loss:  87.40889226645231   Train Accuracy : 97.552\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  143   Loss:  85.85397160798311   Train Accuracy : 97.6\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  144   Loss:  83.91406492888927   Train Accuracy : 97.644\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  145   Loss:  83.12659116089344   Train Accuracy : 97.79\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  146   Loss:  83.70232670009136   Train Accuracy : 97.642\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  147   Loss:  83.32623889297247   Train Accuracy : 97.802\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  148   Loss:  81.33471094071865   Train Accuracy : 97.874\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  149   Loss:  83.17885553836823   Train Accuracy : 97.694\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  150   Loss:  80.3532292097807   Train Accuracy : 97.862\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  151   Loss:  82.40555837750435   Train Accuracy : 97.738\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  152   Loss:  80.88750081509352   Train Accuracy : 97.778\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  153   Loss:  80.90479569137096   Train Accuracy : 97.854\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  154   Loss:  81.01730946451426   Train Accuracy : 97.84\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  155   Loss:  79.16305620223284   Train Accuracy : 97.944\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  156   Loss:  79.93319507688284   Train Accuracy : 97.87\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  157   Loss:  78.13371481001377   Train Accuracy : 98.088\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  158   Loss:  78.97261601686478   Train Accuracy : 97.966\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  159   Loss:  77.8812999650836   Train Accuracy : 98.034\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  160   Loss:  77.65083077549934   Train Accuracy : 98.098\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  161   Loss:  74.62152303755283   Train Accuracy : 98.202\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  162   Loss:  73.96932457387447   Train Accuracy : 98.318\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  163   Loss:  72.19046278297901   Train Accuracy : 98.414\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  164   Loss:  73.31626012176275   Train Accuracy : 98.338\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  165   Loss:  71.32668513804674   Train Accuracy : 98.434\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  166   Loss:  73.09265138208866   Train Accuracy : 98.368\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  167   Loss:  72.8331084176898   Train Accuracy : 98.338\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  168   Loss:  70.72634835541248   Train Accuracy : 98.442\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  169   Loss:  70.53508924692869   Train Accuracy : 98.546\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  170   Loss:  71.53373745083809   Train Accuracy : 98.48\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  171   Loss:  71.3041432723403   Train Accuracy : 98.438\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  172   Loss:  71.05217205733061   Train Accuracy : 98.402\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  173   Loss:  69.16474988311529   Train Accuracy : 98.568\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  174   Loss:  69.94123089313507   Train Accuracy : 98.574\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  175   Loss:  69.88553208112717   Train Accuracy : 98.518\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  176   Loss:  69.34788547456264   Train Accuracy : 98.55\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  177   Loss:  67.94186411798   Train Accuracy : 98.554\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  178   Loss:  66.77067498862743   Train Accuracy : 98.634\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  179   Loss:  68.796875461936   Train Accuracy : 98.554\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  180   Loss:  66.87234804406762   Train Accuracy : 98.634\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  181   Loss:  64.9725684300065   Train Accuracy : 98.74\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  182   Loss:  66.30655177682638   Train Accuracy : 98.702\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  183   Loss:  65.83159999549389   Train Accuracy : 98.734\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  184   Loss:  64.48032627999783   Train Accuracy : 98.77\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  185   Loss:  63.49866630882025   Train Accuracy : 98.806\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  186   Loss:  63.64753641933203   Train Accuracy : 98.816\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  187   Loss:  63.72803566232324   Train Accuracy : 98.818\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  188   Loss:  64.10369922965765   Train Accuracy : 98.826\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  189   Loss:  64.57832529395819   Train Accuracy : 98.808\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  190   Loss:  62.687996327877045   Train Accuracy : 98.778\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 89 %\n",
      "Epoch:  191   Loss:  63.70243597775698   Train Accuracy : 98.84\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  192   Loss:  63.26682072877884   Train Accuracy : 98.92\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  193   Loss:  63.79350396990776   Train Accuracy : 98.804\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  194   Loss:  63.200417436659336   Train Accuracy : 98.888\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  195   Loss:  64.05184936523438   Train Accuracy : 98.82\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  196   Loss:  63.216602467000484   Train Accuracy : 98.896\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  197   Loss:  60.856789872050285   Train Accuracy : 98.932\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  198   Loss:  62.414130970835686   Train Accuracy : 98.942\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  199   Loss:  61.997017215937376   Train Accuracy : 98.914\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  200   Loss:  61.143398985266685   Train Accuracy : 98.972\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n"
     ]
    }
   ],
   "source": [
    "# ======================== Function to get the test accuracy ===============================================================================\n",
    "def test():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.train(False)\n",
    "  with torch.no_grad():\n",
    "    for i,(images,labels)in enumerate(testloader):\n",
    "      if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "      outputs = model(Variable(images))\n",
    "      labels = Variable(labels)\n",
    "      _,predicted = outputs.max(1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted.eq(labels)).sum().item()\n",
    "    print('Test accuracy: %d %%' % (\n",
    "  100 * correct / total))\n",
    "  return 100*(correct/total)\n",
    "\n",
    "#======================================================= Training =========================================================================\n",
    "num_epochs = 200  # Train for 150 epochs\n",
    "start_epoch = 0\n",
    "\n",
    "total_step = len(trainloader)\n",
    "train_loss = []  # Store the train_loss per epoch\n",
    "test_accuracy = [] # Store the test_accuracy per epoch\n",
    "for epoch in range(start_epoch,num_epochs+1):\n",
    "  model.train(True)\n",
    "  epoch_loss  = 0\n",
    "  i_count = 0\n",
    "  acc_total = 0\n",
    "  for i,(images,labels) in enumerate(trainloader):\n",
    "    if torch.cuda.is_available():\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "    labels = Variable(labels)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(Variable(images))\n",
    "    loss = criterion(outputs,labels)\n",
    "    epoch_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _,predicted = outputs.max(1)\n",
    "    denom = labels.size(0)\n",
    "    correct = predicted.eq(labels).sum().item()\n",
    "    acc = 100*(correct/denom)\n",
    "    acc_total += acc\n",
    "    i_count = i_count + 1\n",
    "    \n",
    "    #if(i%20 == 0):  # Print the loss per 20 iterations\n",
    "      #print(\"Epoch: \",epoch,\" \",\"Iteration: \",i,\" loss: \",loss.item(),\" Train_iter Accuracy: \",acc)\n",
    "  schedule.step()\n",
    "  train_loss.append(epoch_loss)\n",
    "  print(\"Epoch: \",epoch,\" \",\"Loss: \",epoch_loss,\" \",\"Train Accuracy :\",acc_total/i_count) # Print train accuracy per epoch\n",
    "  print('\\n')\n",
    "  test_acc = test()      # Print the test accuracy per epoch\n",
    "  test_accuracy.append(test_acc)\n",
    "  \n",
    "  if(epoch%50 == 0):       # Save the model every 50 epoch\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'acc' : test_acc,\n",
    "        'optim':optimizer.state_dict(),\n",
    "        'epoch' : epoch\n",
    "    }\n",
    "    path = './models/VGG16-flex-v10-Maxpools-' + 'model_' + str(int(epoch)) +'_' + str(int(test_acc))+'.pth'\n",
    "    torch.save(state,path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 89 %\n",
      "89.87\n",
      "Accuracy of plane : 97 %\n",
      "Accuracy of   car : 96 %\n",
      "Accuracy of  bird : 86 %\n",
      "Accuracy of   cat : 74 %\n",
      "Accuracy of  deer : 93 %\n",
      "Accuracy of   dog : 87 %\n",
      "Accuracy of  frog : 98 %\n",
      "Accuracy of horse : 90 %\n",
      "Accuracy of  ship : 95 %\n",
      "Accuracy of truck : 96 %\n"
     ]
    }
   ],
   "source": [
    "#======================================= Testing ===================================================================================================\n",
    "test_acc = test() # Test error\n",
    "print(test_acc)\n",
    "\n",
    "# Per class accuracy\n",
    "class_correct = list(0. for i in range(10)) # Individual class error\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4b14cecb986f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     plt.plot(\n\u001b[0;32m----> 4\u001b[0;31m         100 * history[c], label=c)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_acc', test_accuracy]:\n",
    "    plt.plot(\n",
    "        100 * history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
