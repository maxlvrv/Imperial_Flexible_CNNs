{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlavrov/anaconda3/envs/meng/lib/python3.7/site-packages/foolbox/models/pytorch.py:37: UserWarning: The PyTorch model is in training mode and therefore might not be deterministic. Call the eval() method to set it in evaluation mode if this is not intended.\n",
      "  \"The PyTorch model is in training mode and therefore might\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8390000462532043\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cfa83bf30119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0madvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# calculate and report the robust accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/meng/lib/python3.7/site-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# run the actual attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mxpcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/meng/lib/python3.7/site-packages/foolbox/attacks/boundary_attack.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mconverged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_steps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_step_convergance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mconverged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                 \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mconverged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_kd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/meng/lib/python3.7/site-packages/eagerpy/tensor/base.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import eagerpy as ep\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "import foolbox.attacks as fa\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models.VGG16_with_flex_v5 import *\n",
    "\n",
    "epsilons = [0.0, 0.03, 0.1, 0.3]\n",
    "#epsilons = [0, .3]\n",
    "\n",
    "# ======================================== prepare the dataset ==========================================================================================\n",
    "mean_cifar10 = [0.485, 0.456, 0.406]   \n",
    "std_cifar10 = [0.229, 0.224, 0.225]\n",
    "batch_size = 1000\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../FlexibleCNNs/data', train=False, download=False, transform=transform_test)\n",
    "\n",
    "sampler_test = list(range(0, len(testset), 10))\n",
    "testset_samp = torch.utils.data.Subset(testset, sampler_test)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset_samp, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "model = VGG16().to(\"cuda\")\n",
    "preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "fmodel = PyTorchModel(model, bounds=(-2.117, 2.64), preprocessing=preprocessing)\n",
    "\n",
    "# Load the pretrained model\n",
    "state = torch.load('./models/VGG16-flex-v5-block1-model_150_90.pth')\n",
    "model.load_state_dict(state['model']) \n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # get data and test the model\n",
    "        # wrapping the tensors with ep.astensors is optional, but it allows\n",
    "        # us to work with EagerPy tensors in the following\n",
    "        print(accuracy(fmodel, images.cuda(), labels.cuda()))\n",
    "\n",
    "        # apply the attack\n",
    "        attack = fa.boundary_attack.BoundaryAttack(\n",
    "        steps=250,\n",
    "        )\n",
    "\n",
    "        advs, _, success = attack(fmodel, images.cuda(), labels.cuda(), epsilons=epsilons)\n",
    "\n",
    "        # calculate and report the robust accuracy\n",
    "        robust_accuracy = 1 - success.float32().mean(axis=-1)\n",
    "        for eps, acc in zip(epsilons, robust_accuracy):\n",
    "            print(eps, acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlavrov/anaconda3/envs/meng/lib/python3.7/site-packages/foolbox/models/pytorch.py:37: UserWarning: The PyTorch model is in training mode and therefore might not be deterministic. Call the eval() method to set it in evaluation mode if this is not intended.\n",
      "  \"The PyTorch model is in training mode and therefore might\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8100000023841858\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[10, 3, 32, 32]' is invalid for input of size 307200",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-486635c1acbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[10, 3, 32, 32]' is invalid for input of size 307200"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import eagerpy as ep\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "import foolbox.attacks as fa\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models.VGG16_with_flex_v5 import *\n",
    "\n",
    "epsilons = [0.0, 0.03, 0.1, 0.3]\n",
    "#epsilons = [0, .3]\n",
    "\n",
    "# ======================================== prepare the dataset ==========================================================================================\n",
    "mean_cifar10 = [0.485, 0.456, 0.406]   \n",
    "std_cifar10 = [0.229, 0.224, 0.225]\n",
    "batch_size = 1\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../FlexibleCNNs/data', train=False, download=False, transform=transform_test)\n",
    "\n",
    "sampler_test = list(range(0, len(testset), 100))\n",
    "testset_samp = torch.utils.data.Subset(testset, sampler_test)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset_samp, batch_size=100, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "model = VGG16().to(\"cuda\")\n",
    "preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "fmodel = PyTorchModel(model, bounds=(-2.117, 2.64), preprocessing=preprocessing)\n",
    "\n",
    "# Load the pretrained model\n",
    "state = torch.load('./models/VGG16-flex-v5-block1-model_150_90.pth')\n",
    "model.load_state_dict(state['model']) \n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # get data and test the model\n",
    "        # wrapping the tensors with ep.astensors is optional, but it allows\n",
    "        # us to work with EagerPy tensors in the following\n",
    "        print(accuracy(fmodel, images.cuda(), labels.cuda()))\n",
    "\n",
    "        # apply the attack\n",
    "        attack = fa.boundary_attack.BoundaryAttack(\n",
    "        steps=2500,\n",
    "        )\n",
    "\n",
    "        advs, _, success = attack(fmodel, images.cuda(), labels.cuda(), epsilons=epsilons)\n",
    "        \n",
    "        \n",
    "        images = torch.stack(advs)\n",
    "        images = torch.reshape(images[0,:], (100, 3, 32, 32))\n",
    "        \n",
    "        outputs = model(images.cuda())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum().item()\n",
    "\n",
    "        print('0.0 Accuracy on the test dataset is: %f %%' % (\n",
    "            100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_test = list(range(0, len(testset), 10))\n",
    "testset_samp = torch.utils.data.Subset(testset, sampler_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=True, num_workers=2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "            images, labels = data\n",
    "            #images = images.clone().detach()\n",
    "            #labels = labels.clone().detach()\n",
    "    #images, labels = ep.astensors(*samples(fmodel, dataset=testloader, batchsize=100, shape=(32, 32), bounds=(-1, 1)))\n",
    "            print(accuracy(fmodel, images.cuda(), labels.cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test dataset is: 88.500000 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# ======================================== prepare the dataset ==========================================================================================\n",
    "mean_cifar10 = [0.485, 0.456, 0.406]   \n",
    "std_cifar10 = [0.229, 0.224, 0.225]\n",
    "batch_size = 1\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../FlexibleCNNs/data', train=False, download=False, transform=transform_test)\n",
    "sampler_test = list(range(0, len(testset), 10))\n",
    "testset_samp = torch.utils.data.Subset(testset, sampler_test)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset_samp, batch_size=1000, shuffle=True, num_workers=2)\n",
    "\n",
    "#evaluate model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        #print(images.size())\n",
    "        outputs = model(images.cuda())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum().item()\n",
    "\n",
    "print('Accuracy on the test dataset is: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlavrov/anaconda3/envs/meng/lib/python3.7/site-packages/foolbox/models/pytorch.py:37: UserWarning: The PyTorch model is in training mode and therefore might not be deterministic. Call the eval() method to set it in evaluation mode if this is not intended.\n",
      "  \"The PyTorch model is in training mode and therefore might\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 Accuracy on the test dataset is: 86.000000 %\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-320d374ff95f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mrob_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epsilon: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Robust Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrob_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import eagerpy as ep\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "import foolbox.attacks as fa\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models.VGG16_with_flex_v5 import *\n",
    "\n",
    "#epsilons = [0.0, 0.03, 0.1, 0.3]\n",
    "epsilons = [0, .3]\n",
    "#epsilons = [1, 25000]\n",
    "\n",
    "# ======================================== prepare the dataset ==========================================================================================\n",
    "mean_cifar10 = [0.485, 0.456, 0.406]   \n",
    "std_cifar10 = [0.229, 0.224, 0.225]\n",
    "batch_size = 100\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../FlexibleCNNs/data', train=False, download=False, transform=transform_test)\n",
    "\n",
    "sampler_test = list(range(0, len(testset), 100))\n",
    "testset_samp = torch.utils.data.Subset(testset, sampler_test)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset_samp, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "model = VGG16().to(\"cuda\")\n",
    "preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "fmodel = PyTorchModel(model, bounds=(-2.117, 2.64), preprocessing=preprocessing)\n",
    "\n",
    "# Load the pretrained model\n",
    "state = torch.load('./models/VGG16-flex-v5-block1-model_150_90.pth')\n",
    "model.load_state_dict(state['model']) \n",
    "\n",
    "model.eval()\n",
    "\n",
    "def test(steps):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.train(False)\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "\n",
    "            # apply the attack\n",
    "            attack = fa.boundary_attack.BoundaryAttack(\n",
    "            steps=steps,\n",
    "            )\n",
    "\n",
    "            advs, _, success = attack(fmodel, images.cuda(), labels.cuda(), epsilons=epsilons)\n",
    "            \n",
    "            #images = torch.tensor(advs)\n",
    "            \n",
    "            robust_accuracy = 1 - success.double().mean(axis=-1)\n",
    "            \n",
    "            outputs = model(images.cuda())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.cuda()).sum().item()\n",
    "            print('0.0 Accuracy on the test dataset is: %f %%' % (\n",
    "            100 * correct / total))\n",
    "        \n",
    "    return robust_accuracy\n",
    "        \n",
    "for eps in epsilons:\n",
    "    rob_acc = test(eps)\n",
    "    print(\"Epsilon: \", eps, \"Robust Accuracy:\", rob_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
