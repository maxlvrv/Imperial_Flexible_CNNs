{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([3, 36, 138])\n",
      " frog  bird plane horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " #===================================================== Import libraries ================================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn \n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from models.VGG16 import *\n",
    "\n",
    "\n",
    "# =================================================== Prepare the dataset ===============================================================================\n",
    "\n",
    "mean_cifar10 = [0.485, 0.456, 0.406]  # Mean and Std value hase been taken from a github implmentation online.\n",
    "std_cifar10 = [0.229, 0.224, 0.225]\n",
    "batch_size = 100\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10,std_cifar10),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../FlexibleCNNs/data', train=True, download= True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../FlexibleCNNs/data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # 10 Classes of the cifar-10\n",
    "\n",
    "# ========================================== Visualising the dataset ==========================================================================\n",
    "std= torch.FloatTensor(std_cifar10)\n",
    "mean = torch.FloatTensor(mean_cifar10)\n",
    "mean = mean[:,None,None]\n",
    "std = std[:,None,None]\n",
    "def imshow(img):\n",
    "    print(img.size())\n",
    "    img = img*std + mean     # unnormalize\n",
    "    \n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,775,646 total parameters.\n",
      "14,775,646 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================== Model initialisation, Loss function and Optimizer =====================================\n",
    "model = VGG16()\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.001,momentum = 0.9,weight_decay = 0.006)\n",
    "schedule = torch.optim.lr_scheduler.StepLR(optimizer,step_size=20,gamma = 0.7)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} trainable parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout2d(p=0.3, inplace=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout2d(p=0.4, inplace=False)\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Dropout2d(p=0.4, inplace=False)\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Dropout2d(p=0.4, inplace=False)\n",
       "  )\n",
       "  (block5): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Dropout2d(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlavrov/anaconda3/envs/meng/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0   Loss:  1081.0219116210938   Train Accuracy : 17.598\n",
      "\n",
      "\n",
      "Test accuracy: 15 %\n",
      "Epoch:  1   Loss:  953.3859663009644   Train Accuracy : 26.65\n",
      "\n",
      "\n",
      "Test accuracy: 27 %\n",
      "Epoch:  2   Loss:  883.717242360115   Train Accuracy : 32.954\n",
      "\n",
      "\n",
      "Test accuracy: 36 %\n",
      "Epoch:  3   Loss:  835.3956513404846   Train Accuracy : 37.586\n",
      "\n",
      "\n",
      "Test accuracy: 42 %\n",
      "Epoch:  4   Loss:  799.9877156019211   Train Accuracy : 41.302\n",
      "\n",
      "\n",
      "Test accuracy: 45 %\n",
      "Epoch:  5   Loss:  764.4209824800491   Train Accuracy : 45.042\n",
      "\n",
      "\n",
      "Test accuracy: 52 %\n",
      "Epoch:  6   Loss:  727.0626668930054   Train Accuracy : 48.52\n",
      "\n",
      "\n",
      "Test accuracy: 55 %\n",
      "Epoch:  7   Loss:  691.8528804779053   Train Accuracy : 52.11\n",
      "\n",
      "\n",
      "Test accuracy: 59 %\n",
      "Epoch:  8   Loss:  649.9034715890884   Train Accuracy : 55.646\n",
      "\n",
      "\n",
      "Test accuracy: 62 %\n",
      "Epoch:  9   Loss:  617.1148545145988   Train Accuracy : 58.61\n",
      "\n",
      "\n",
      "Test accuracy: 63 %\n",
      "Epoch:  10   Loss:  589.4398677945137   Train Accuracy : 60.614\n",
      "\n",
      "\n",
      "Test accuracy: 65 %\n",
      "Epoch:  11   Loss:  559.3854498267174   Train Accuracy : 63.256\n",
      "\n",
      "\n",
      "Test accuracy: 68 %\n",
      "Epoch:  12   Loss:  539.8266351222992   Train Accuracy : 64.796\n",
      "\n",
      "\n",
      "Test accuracy: 70 %\n",
      "Epoch:  13   Loss:  515.0698412060738   Train Accuracy : 66.844\n",
      "\n",
      "\n",
      "Test accuracy: 72 %\n",
      "Epoch:  14   Loss:  495.426500082016   Train Accuracy : 68.3\n",
      "\n",
      "\n",
      "Test accuracy: 74 %\n",
      "Epoch:  15   Loss:  476.3282401561737   Train Accuracy : 70.124\n",
      "\n",
      "\n",
      "Test accuracy: 75 %\n",
      "Epoch:  16   Loss:  458.4868286252022   Train Accuracy : 71.698\n",
      "\n",
      "\n",
      "Test accuracy: 77 %\n",
      "Epoch:  17   Loss:  436.6255967617035   Train Accuracy : 73.368\n",
      "\n",
      "\n",
      "Test accuracy: 78 %\n",
      "Epoch:  18   Loss:  421.77433347702026   Train Accuracy : 74.49\n",
      "\n",
      "\n",
      "Test accuracy: 79 %\n",
      "Epoch:  19   Loss:  397.063200712204   Train Accuracy : 76.492\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  20   Loss:  381.886647939682   Train Accuracy : 77.364\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  21   Loss:  370.1601036787033   Train Accuracy : 78.458\n",
      "\n",
      "\n",
      "Test accuracy: 81 %\n",
      "Epoch:  22   Loss:  361.39389246702194   Train Accuracy : 78.908\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  23   Loss:  353.77851101756096   Train Accuracy : 79.788\n",
      "\n",
      "\n",
      "Test accuracy: 82 %\n",
      "Epoch:  24   Loss:  341.7522631585598   Train Accuracy : 80.498\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  25   Loss:  335.4933533668518   Train Accuracy : 81.046\n",
      "\n",
      "\n",
      "Test accuracy: 83 %\n",
      "Epoch:  26   Loss:  328.6772732138634   Train Accuracy : 81.534\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  27   Loss:  317.89646142721176   Train Accuracy : 82.282\n",
      "\n",
      "\n",
      "Test accuracy: 84 %\n",
      "Epoch:  28   Loss:  314.3304829597473   Train Accuracy : 82.608\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  29   Loss:  306.7988987863064   Train Accuracy : 83.01\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  30   Loss:  297.6625092923641   Train Accuracy : 83.668\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  31   Loss:  295.0530686378479   Train Accuracy : 83.926\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  32   Loss:  287.3723638653755   Train Accuracy : 84.274\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  33   Loss:  278.40041172504425   Train Accuracy : 84.97\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  34   Loss:  275.4975913763046   Train Accuracy : 85.196\n",
      "\n",
      "\n",
      "Test accuracy: 85 %\n",
      "Epoch:  35   Loss:  267.3694893717766   Train Accuracy : 85.798\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  36   Loss:  267.4847286939621   Train Accuracy : 85.794\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  37   Loss:  261.46204632520676   Train Accuracy : 86.254\n",
      "\n",
      "\n",
      "Test accuracy: 86 %\n",
      "Epoch:  38   Loss:  256.4919377565384   Train Accuracy : 86.406\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  39   Loss:  234.74701902270317   Train Accuracy : 87.942\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  40   Loss:  222.04596307873726   Train Accuracy : 88.892\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  41   Loss:  221.30722925066948   Train Accuracy : 88.984\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  42   Loss:  215.74876655638218   Train Accuracy : 89.302\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  43   Loss:  210.79379269480705   Train Accuracy : 89.626\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  44   Loss:  211.02374199032784   Train Accuracy : 89.51\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  45   Loss:  205.0750776976347   Train Accuracy : 89.972\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  46   Loss:  205.7519105821848   Train Accuracy : 89.624\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  47   Loss:  203.22142048180103   Train Accuracy : 90.032\n",
      "\n",
      "\n",
      "Test accuracy: 87 %\n",
      "Epoch:  48   Loss:  202.3265746384859   Train Accuracy : 90.08\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  49   Loss:  197.08279764652252   Train Accuracy : 90.51\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  50   Loss:  193.51844182610512   Train Accuracy : 90.818\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  51   Loss:  195.97142674028873   Train Accuracy : 90.568\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  52   Loss:  188.8117674589157   Train Accuracy : 91.018\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  53   Loss:  187.54331615567207   Train Accuracy : 91.042\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  54   Loss:  181.0814728140831   Train Accuracy : 91.416\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  55   Loss:  178.81717756390572   Train Accuracy : 91.574\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  56   Loss:  179.364001840353   Train Accuracy : 91.64\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  57   Loss:  177.50489892065525   Train Accuracy : 91.758\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  58   Loss:  180.61306692659855   Train Accuracy : 91.38\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  59   Loss:  160.69536192715168   Train Accuracy : 92.75\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  60   Loss:  151.2079391181469   Train Accuracy : 93.352\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  61   Loss:  146.1031259149313   Train Accuracy : 93.802\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  62   Loss:  145.85763461887836   Train Accuracy : 93.818\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  63   Loss:  143.89577010273933   Train Accuracy : 93.908\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  64   Loss:  141.1088718622923   Train Accuracy : 94.108\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  65   Loss:  139.02687264978886   Train Accuracy : 94.154\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  66   Loss:  137.17920354008675   Train Accuracy : 94.17\n",
      "\n",
      "\n",
      "Test accuracy: 88 %\n",
      "Epoch:  67   Loss:  136.29695115983486   Train Accuracy : 94.242\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  68   Loss:  135.4376315921545   Train Accuracy : 94.36\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  69   Loss:  134.43572092056274   Train Accuracy : 94.366\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  70   Loss:  132.72317893058062   Train Accuracy : 94.57\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  71   Loss:  133.5026840865612   Train Accuracy : 94.408\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  72   Loss:  133.69863265752792   Train Accuracy : 94.398\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  73   Loss:  129.1507889404893   Train Accuracy : 94.642\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  74   Loss:  128.96016232669353   Train Accuracy : 94.702\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  75   Loss:  130.89303340017796   Train Accuracy : 94.62\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  76   Loss:  129.09969063848257   Train Accuracy : 94.69\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  77   Loss:  130.13950233906507   Train Accuracy : 94.48\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  78   Loss:  123.99600376933813   Train Accuracy : 95.02\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  79   Loss:  112.93853026628494   Train Accuracy : 95.642\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  80   Loss:  104.8333890363574   Train Accuracy : 96.362\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  81   Loss:  105.38321602344513   Train Accuracy : 96.312\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  82   Loss:  100.51078420877457   Train Accuracy : 96.596\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  83   Loss:  98.7427654787898   Train Accuracy : 96.692\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  84   Loss:  98.00559562444687   Train Accuracy : 96.66\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  85   Loss:  96.15066178888083   Train Accuracy : 96.858\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  86   Loss:  94.48545684665442   Train Accuracy : 96.908\n",
      "\n",
      "\n",
      "Test accuracy: 89 %\n",
      "Epoch:  87   Loss:  96.79717555642128   Train Accuracy : 96.694\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  88   Loss:  95.08785231411457   Train Accuracy : 96.836\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  89   Loss:  92.10178296267986   Train Accuracy : 97.012\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  90   Loss:  91.90884272754192   Train Accuracy : 97.016\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  91   Loss:  94.39730831235647   Train Accuracy : 96.888\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  92   Loss:  94.19479466974735   Train Accuracy : 96.826\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  93   Loss:  93.1453483402729   Train Accuracy : 96.9\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  94   Loss:  90.44818836450577   Train Accuracy : 97.078\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  95   Loss:  91.31724425405264   Train Accuracy : 96.956\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  96   Loss:  92.20501195639372   Train Accuracy : 96.876\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  97   Loss:  92.14326270669699   Train Accuracy : 96.954\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  98   Loss:  91.48192447423935   Train Accuracy : 96.996\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  99   Loss:  86.22750509530306   Train Accuracy : 97.292\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  100   Loss:  82.66153486818075   Train Accuracy : 97.49\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  101   Loss:  78.54547502845526   Train Accuracy : 97.814\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  102   Loss:  77.75619292259216   Train Accuracy : 97.91\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  103   Loss:  77.19319523125887   Train Accuracy : 97.892\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  104   Loss:  76.70385921746492   Train Accuracy : 97.81\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  105   Loss:  74.65389918535948   Train Accuracy : 98.058\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  106   Loss:  75.91140493005514   Train Accuracy : 98.046\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  107   Loss:  73.22698614001274   Train Accuracy : 98.054\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  108   Loss:  72.56929314881563   Train Accuracy : 98.294\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  109   Loss:  72.19866394996643   Train Accuracy : 98.194\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  110   Loss:  70.38284438848495   Train Accuracy : 98.31\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  111   Loss:  71.62808049470186   Train Accuracy : 98.232\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  112   Loss:  71.64696085453033   Train Accuracy : 98.2\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  113   Loss:  69.63948125392199   Train Accuracy : 98.22\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  114   Loss:  70.17563091218472   Train Accuracy : 98.296\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  115   Loss:  69.32215867191553   Train Accuracy : 98.338\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  116   Loss:  69.85541165620089   Train Accuracy : 98.284\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  117   Loss:  72.51674719899893   Train Accuracy : 98.072\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  118   Loss:  71.44310096651316   Train Accuracy : 98.258\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  119   Loss:  67.50121217221022   Train Accuracy : 98.436\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  120   Loss:  65.09782242774963   Train Accuracy : 98.558\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  121   Loss:  63.76771700754762   Train Accuracy : 98.63\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  122   Loss:  62.01375424861908   Train Accuracy : 98.776\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  123   Loss:  62.957219801843166   Train Accuracy : 98.704\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  124   Loss:  61.102145835757256   Train Accuracy : 98.846\n",
      "\n",
      "\n",
      "Test accuracy: 90 %\n",
      "Epoch:  125   Loss:  60.1938185878098   Train Accuracy : 98.84\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  126   Loss:  60.54096984118223   Train Accuracy : 98.89\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  127   Loss:  61.1316607221961   Train Accuracy : 98.742\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  128   Loss:  60.42287262156606   Train Accuracy : 98.828\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  129   Loss:  60.36834305524826   Train Accuracy : 98.844\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  130   Loss:  59.646380215883255   Train Accuracy : 98.908\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  131   Loss:  59.68523521348834   Train Accuracy : 98.922\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  132   Loss:  59.328112073242664   Train Accuracy : 98.882\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  133   Loss:  58.38714787364006   Train Accuracy : 98.936\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  134   Loss:  58.74052977561951   Train Accuracy : 98.952\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  135   Loss:  58.31798905134201   Train Accuracy : 98.976\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  136   Loss:  59.09888460487127   Train Accuracy : 98.92\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  137   Loss:  59.267531372606754   Train Accuracy : 98.904\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  138   Loss:  59.198566783219576   Train Accuracy : 98.808\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  139   Loss:  57.30456483736634   Train Accuracy : 99.018\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  140   Loss:  57.61856758594513   Train Accuracy : 99.01\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  141   Loss:  56.38724111020565   Train Accuracy : 99.06\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  142   Loss:  56.013647846877575   Train Accuracy : 99.098\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  143   Loss:  56.56375499069691   Train Accuracy : 99.014\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  144   Loss:  54.78896052017808   Train Accuracy : 99.094\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  145   Loss:  55.33038864284754   Train Accuracy : 99.092\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  146   Loss:  55.024863082915545   Train Accuracy : 99.124\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  147   Loss:  54.58325031027198   Train Accuracy : 99.184\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  148   Loss:  54.69518010318279   Train Accuracy : 99.192\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n",
      "Epoch:  149   Loss:  53.375815365463495   Train Accuracy : 99.302\n",
      "\n",
      "\n",
      "Test accuracy: 91 %\n"
     ]
    }
   ],
   "source": [
    "# ======================== Function to get the test accuracy ===============================================================================\n",
    "def test():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.train(False)\n",
    "  with torch.no_grad():\n",
    "    for i,(images,labels)in enumerate(testloader):\n",
    "      if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "      outputs = model(Variable(images))\n",
    "      labels = Variable(labels)\n",
    "      _,predicted = outputs.max(1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted.eq(labels)).sum().item()\n",
    "    print('Test accuracy: %d %%' % (\n",
    "  100 * correct / total))\n",
    "  return 100*(correct/total)\n",
    "\n",
    "#======================================================= Training =========================================================================\n",
    "num_epochs = 150  # Train for 200 epochs\n",
    "start_epoch = 0\n",
    "\n",
    "total_step = len(trainloader)\n",
    "train_loss = []  # Store the train_loss per epoch\n",
    "test_accuracy = [] # Store the test_accuracy per epoch\n",
    "for epoch in range(start_epoch,num_epochs):\n",
    "  model.train(True)\n",
    "  schedule.step()\n",
    "  epoch_loss  = 0\n",
    "  i_count = 0\n",
    "  acc_total = 0\n",
    "  for i,(images,labels) in enumerate(trainloader):\n",
    "    if torch.cuda.is_available():\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "    labels = Variable(labels)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(Variable(images))\n",
    "    loss = criterion(outputs,labels)\n",
    "    epoch_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _,predicted = outputs.max(1)\n",
    "    denom = labels.size(0)\n",
    "    correct = predicted.eq(labels).sum().item()\n",
    "    acc = 100*(correct/denom)\n",
    "    acc_total += acc\n",
    "    i_count = i_count + 1\n",
    "    \n",
    "    #if(i%20 == 0):  # Print the loss per 20 iterations\n",
    "      #print(\"Epoch: \",epoch,\" \",\"Iteration: \",i,\" loss: \",loss.item(),\" Train_iter Accuracy: \",acc)\n",
    "  train_loss.append(epoch_loss)\n",
    "  print(\"Epoch: \",epoch,\" \",\"Loss: \",epoch_loss,\" \",\"Train Accuracy :\",acc_total/i_count) # Print train accuracy per epoch\n",
    "  print('\\n')\n",
    "  test_acc = test()      # Print the test accuracy per epoch\n",
    "  test_accuracy.append(test_acc)\n",
    "  \n",
    "  if(epoch%50 == 0):       # Save the model every 50 epoch\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'acc' : test_acc,\n",
    "        'optim':optimizer.state_dict(),\n",
    "        'epoch' : epoch\n",
    "    }\n",
    "    path = './base_noMaxpool_' + 'model_' + str(int(epoch)) +'_' + str(int(test_acc))+'.pth'\n",
    "    torch.save(state,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 91 %\n",
      "91.39\n",
      "Accuracy of plane : 93 %\n",
      "Accuracy of   car : 100 %\n",
      "Accuracy of  bird : 84 %\n",
      "Accuracy of   cat : 76 %\n",
      "Accuracy of  deer : 91 %\n",
      "Accuracy of   dog : 90 %\n",
      "Accuracy of  frog : 94 %\n",
      "Accuracy of horse : 96 %\n",
      "Accuracy of  ship : 100 %\n",
      "Accuracy of truck : 100 %\n"
     ]
    }
   ],
   "source": [
    "#======================================= Testing ===================================================================================================\n",
    "test_acc = test() # Test error\n",
    "print(test_acc)\n",
    "\n",
    "# Per class accuracy\n",
    "class_correct = list(0. for i in range(10)) # Individual class error\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
